<div id=toc></div>

# Table of Contents

- [hep-th](#hep-th) [Total: 10]
- [cs.SC](#cs.SC) [Total: 2]
- [hep-ph](#hep-ph) [Total: 21]


<div id='hep-th'></div>

# hep-th [[Back]](#toc)

### [1] [Total instanton restriction via multiverse interference: Noncompact gauge theories and (-1)-form symmetries](https://arxiv.org/abs/2508.00050)
*Alonso Perez-Lona,Eric Sharpe,Xingyang Yu,Hao Zhang*

Main category: hep-th

TL;DR: This paper explores decomposition in local quantum field theories (QFTs) with a continuous family of universes, enabling the consistent elimination of instantons via topological gauging of (-1)-form symmetry; it applies this to 2D U(1) and R gauge theories, clarifies the Gross-Taylor string interpretation, and examines anomaly relations via dyon-like universe rotations, while discussing connections to the Tanizaki-Unsal construction and the adelic solenoid.


<details>
  <summary>Details</summary>
Motivation: To understand how continuous decomposition in local QFTs can eliminate instantons and clarify dualities and anomalies, particularly in 2D gauge theories, by leveraging topological gauging of (-1)-form symmetries.

Method: Analyzing decomposition via topological gauging of (-1)-form symmetry in 2D gauge theories, particularly U(1) and R gauge groups; applying decomposition to study pure Yang-Mills, Maxwell theory, and supersymmetric GLSMs; examining anomaly matching through dyon-like effects across universes.

Result: Demonstrated that instantons can be consistently eliminated in local QFTs via continuous decomposition and topological gauging; showed equivalence to changing U(1) to R in 2D; clarified the Gross-Taylor string interpretation; identified universe-rotating analogues of the Witten effect relating anomalies; discussed limits of the Tanizaki-Unsal construction in terms of the adelic solenoid.

Conclusion: Continuous decomposition provides a powerful framework for controlling instantons and understanding dualities and anomalies in 2D QFTs, with implications for string interpretations and potential connections to number-theoretic structures like the adelic solenoid.

Abstract: In this note we consider examples of decomposition (in which a local QFT is
equivalent to a disjoint union of multiple independent theories, known as
universes) where there is a continuous familiy of universes, rather than a
finite or countably infinite collection. In particular, this allows us to
consistently eliminate all instantons in a local QFT via a suitable topological
gauging of the (-1)-form symmetry. In two-dimensional U(1) gauge theories, this
is equivalent to changing the gauge gruop to R. This makes both locality as
well as the instanton restriction explicit. We apply this to clarify the
Gross-Taylor string interpretation of the decomposition of two-dimensional pure
Yang-Mills. We also apply decomposition to study two-dimensional R gauge
theories, such as the pure R Maxwell theory, and two-dimensional supersymmetric
gauged linear sigma models whose gauge groups have factors of R. In that
context, we find that analogues of the Witten effect for dyons, here rotating
between universes, play a role in relating anomalies of the individual
universes to (different) anomalies in the disjoint union. Finally, we discuss
limits of the Tanizaki-Unsal construction, which accomplish instanton
restriction by topologically gauging a Q/Z (-1)-form symmetry, and speculate in
two-dimensional theories on possible interpretations of those limits in terms
of the adelic solenoid.

</details>


### [2] [Volume as an index of a subalgebra](https://arxiv.org/abs/2508.00056)
*Samuel Leutheusser,Hong Liu*

Main category: hep-th

TL;DR: The paper proposes a 'volume-index' relation, linking the volume of bulk subregions in AdS spacetime to the index of inclusion of boundary operator algebras, offering a new algebraic explanation for black hole interior volume growth and complexity.


<details>
  <summary>Details</summary>
Motivation: To understand the holographic meaning of bulk subregion volumes, particularly in black holes, using algebraic quantum field theory and subregion-subalgebra duality.

Method: The authors use subregion-subalgebra duality in AdS/CFT, identifying bulk subregions with boundary von Neumann algebras, and propose that the exponential of the maximal bulk volume equals the index of inclusion of the corresponding boundary subalgebras.

Result: A proposed 'volume-index' relation that equates exponential bulk volume with the index of inclusion; this reframes black hole volume growth as algebraic size change and applies to entanglement and causal wedges, non-additivity of algebras, and potentially de Sitter space.

Conclusion: Bulk geometry, particularly volume, can be understood as an emergent algebraic property via the index of inclusion, providing a new perspective on complexity and spacetime structure in holography.

Abstract: We propose a new way to understand the volume of certain subregions in the
bulk of AdS spacetime by relating it to an algebraic quantity known as the
index of inclusion. This index heuristically measures the relative size of a
subalgebra $\mathcal{N}$ embedded within a larger algebra $\mathcal{M}$.
According to subregion-subalgebra duality, bulk subregions are described by von
Neumann algebras on the boundary. When a causally complete bulk subregion
corresponds to the relative commutant $\mathcal{N}' \cap \mathcal{M}$ -- the
set of operators in $\mathcal{M}$ that commute with $\mathcal{N}$ -- of
boundary subalgebras, we propose that the exponential of the volume of the
maximal volume slice of the subregion equals the index of inclusion. This
``volume-index'' relation provides a new boundary explanation for the growth of
interior volume in black holes, reframing it as a change in the relative size
of operator algebras. It offers a complementary perspective on complexity
growth from the Heisenberg picture, and has a variety of other applications,
including quantifying the relative size of algebras dual to the entanglement
wedge and the causal wedge of a boundary region, as well as quantifying the
violation of additivity of operator algebras in the large $N$ limit. Finally,
it may offer insights into the volume growth of de Sitter space through the
changes in North and South pole observer algebras in time.

</details>


### [3] [Entanglement spreading and emergent locality in Brownian SYK chains](https://arxiv.org/abs/2508.00060)
*Onkar Parrikar,Jatin Narde,Harshit Rajgadia,Sandip Trivedi*

Main category: hep-th

TL;DR: The paper studies the spread of quantum information in a 1D Brownian SYK chain using quantum error correction tools, showing that information spreads within a sharp light-cone defined by the butterfly velocity, consistent with holographic expectations from the Ryu-Takayanagi formula.


<details>
  <summary>Details</summary>
Motivation: To understand how quantum information spreads in chaotic systems and how emergent locality arises, which is crucial for the existence of a geometric bulk dual in holography.

Method: Analytical calculations in a 1D Brownian SYK chain at infinite temperature, tracking the spread of a qudit injected at a point by computing information recovery in intervals over time, leveraging quantum error correction and operator growth concepts.

Result: At strong coupling, the information content in an interval shows a sharp transition at length ℓ ∼ v_B T, indicating a light-cone structure governed by the butterfly velocity; this behavior is described by the FKPP equation, which supports sharp domain wall solutions.

Conclusion: Emergent locality with a sharp light-cone for quantum information spread arises in chaotic systems like the SYK model, supporting the holographic principle and the connection between entanglement, geometry, and quantum error correction.

Abstract: The Ryu-Takayanagi (RT) formula and its interpretation in terms of quantum
error correction (QEC) implies an emergent locality for the spread of quantum
information in holographic CFTs, where information injected at a point in the
boundary theory spreads within a sharp light-cone corresponding to the
butterfly velocity. This emergent locality is a necessary condition for the
existence of a geometric bulk dual with an RT-like formula for entanglement
entropy. In this paper, we use tools from QEC to study the spread of quantum
information and the emergence of a sharp light-cone in an analytically
tractable model of chaotic dynamics, namely a one-dimensional Brownian SYK
chain. We start with an infinite temperature state in this model and inject a
qudit at time $t=0$ at some point $p$ on the chain. We then explicitly
calculate the amount of information of the qudit contained in an interval of
length $2\ell$ (centered around $p$) at some later time $t=T$. We find that at
strong coupling, this quantity shows a sharp transition as a function of $\ell$
from near zero to near maximal correlation. The transition occurs at $\ell \sim
v_B T$, with $v_B$ being the butterfly velocity. Underlying the emergence of
this sharp light-cone is a non-linear generalization of the diffusion equation
called the FKPP equation, which admits sharp domain wall solutions at late
times and strong coupling. These domain wall solutions can be understood on
physical grounds from properties of operator growth in chaotic systems.

</details>


### [4] [The CFT of Sen's Formulation of Chiral Gauge Fields](https://arxiv.org/abs/2508.00199)
*Chris Hull,Neil Lambert*

Main category: hep-th

TL;DR: The paper discusses Sen's action for chiral bosons in 2D and its generalization using two metrics, linking it to conformal field theories and proposing a 'bosonisation' interpretation; it extends this framework to higher-dimensional self-dual gauge fields via a bi-metric action.


<details>
  <summary>Details</summary>
Motivation: To understand the structure of chiral boson actions in two dimensions and generalize them to curved world-sheets using two metrics, while exploring connections to conformal field theories and extending the formalism to higher-dimensional self-dual gauge fields.

Method: Analyzing Sen's action for chiral bosons by introducing a second metric, studying its reduction to known theories (e.g., beta-gamma systems), identifying vertex and line operators, and generalizing the construction to 2k-form gauge fields in d=4k+2 dimensions with self-dual field strengths using a bi-metric or BF-type action.

Result: The flat metric in Sen's action can be generalized to an arbitrary second metric, allowing formulation on curved world-sheets; when metrics coincide, the theory reduces to a non-unitary c=2 CFT; this is interpreted as a bosonisation of two chiral scalars; vertex operators in the chiral scalar theory are identified in Sen's formulation; the framework extends to higher dimensions, where the bi-metric action reduces to a BF-type theory with self-dual fields, representing two self-dual gauge fields rather than a topological theory.

Conclusion: Sen's action for chiral bosons admits a natural generalization with two metrics, providing a geometric and algebraic framework that connects chiral scalar theories, bosonisation, and conformal field theory in 2D, and extends meaningfully to self-dual gauge theories in higher dimensions.

Abstract: Sen's action for chiral bosons in 2 dimensions describes two chiral scalars,
one of which couples to the physical metric and one of which couples to a flat
metric. It has a generalisation in which the flat metric is replaced by an
arbitrary second metric and so can be formulated on any curved world-sheet.
When the two metrics are equal, the theory reduces to a $\beta \gamma$ system,
giving a non-unitary $c=2$ conformal field theory. We argue that the relation
between this and the theory of two chiral bosonic scalars of the same chirality
can be viewed as a \lq bosonisation'. We show that the standard vertex
operators for the chiral scalars are vertex operators and line operators in the
Sen formulation and derive the formulation in the Sen theory of correlation
functions in the chiral scalar theory. The flat space Sen theory can be coupled
to two different world-sheet metrics in such a way that one scalar couples to
one metric and the other to the other metric, so obtaining the general
formulation with two metrics.
  In $d=4k+2$ dimensions, the bi-metric action for a $2k$-form gauge field with
self-dual field strength reduces, when the two metrics are equal, to a
conformal field theory with a $BF$-type action, except that $B$ is a self-dual
$d/2$-form and $F$ is a $d/2$-form field strength, $F=dP$. The self-duality of
$B$ means that this is not a topological theory but instead represents two
self-dual gauge fields. This has a generalisation to a democratic action for
$p$-form gauge fields in any dimension.

</details>


### [5] [Holographic Wilson Loop One-point Functions in ABJM Theory](https://arxiv.org/abs/2508.00281)
*Xiao-Yi Zhang,Yunfeng Jiang,Jun-Bao Wu*

Main category: hep-th

TL;DR: The paper computes correlation functions between a BPS Wilson loop and local operators in ABJM theory using its M-theory dual, showing agreement between holographic calculations and supersymmetric localization in the large-N limit.


<details>
  <summary>Details</summary>
Motivation: To understand the correlation between BPS Wilson loops and local operators in ABJM theory through the AdS/CFT correspondence and verify consistency with existing localization results.

Method: Used the M-theory description of ABJM theory, computing correlators as fluctuations of a probe M2-brane in $AdS_4 \times S^7/\mathbb{Z}_k$, and compared holographic results with supersymmetric localization.

Result: Derived analytic expressions for correlators involving chiral primary operators and the stress-energy tensor; found perfect agreement with localization in the large-N limit with finite k.

Conclusion: Holographic computations in M-theory correctly reproduce field theory results from localization, supporting the validity of the AdS/CFT duality in this BPS sector of ABJM theory.

Abstract: We compute the correlation function between a circular half-BPS Wilson loop
(or straight Wilson line) and a local operator in ABJM theory utilizing its
M-theory description. The local operator can be a $1/3$-BPS single-trace chiral
primary operator or the stress-energy tensor. Using the AdS/CFT correspondence,
these correlators are dual to fluctuations of a probe M2-brane in $AdS_4 \times
S^7/\mathbb{Z}_k$. We derive analytic results for both cases and compare them
with existing results based on supersymmetric localization in the literature.
In the large-$N$ limit with $k$ finite, our holograkphic results exhibit
perfect agreement with localization.

</details>


### [6] [Quasi-Normal Modes and Nonlinear Electrodynamics in Black Hole Phase Transitions](https://arxiv.org/abs/2508.00404)
*Zi-Yu Hou,Yu-Qi Lei,Xian-Hui Ge*

Main category: hep-th

TL;DR: The study explores the link between thermodynamic phase transitions and quasi-normal modes (QNMs) in charged black holes within $F(R)$-Euler-Heisenberg gravity, showing that QNM behavior reflects thermodynamic phase changes, with alignment depending on curvature, charge, angular quantum number $l$, and overtone number $n€.


<details>
  <summary>Details</summary>
Motivation: To understand how thermodynamic phase transitions in black holes are connected to their dynamical properties, specifically through quasi-normal modes in the context of nonlinear electromagnetic fields and modified gravity.

Method: Analyzed the quasi-normal modes spectrum of massless scalar fields in charged black holes with positive curvature in $F(R)$-Euler-Heisenberg gravity, and compared the transition points in QNM slope parameter $K$ with thermodynamic phase transitions identified via heat capacity.

Result: The transition point in the QNM slope parameter $K$ aligns with the thermodynamic phase transition point described by heat capacity under varying curvature and charge; higher $l$ weakens this correspondence, while higher $n$ restores it beyond a threshold.

Conclusion: Thermodynamic phase transitions in black holes encode dynamical information through QNMs, revealing a fundamental connection between thermodynamic and dynamical properties in modified gravity with nonlinear electrodynamics.

Abstract: We investigate the connection between thermodynamic phase transitions and
quasi-normal modes (QNMs) in charged black holes with a positive curvature
constant, within the framework of $F(R)$-Euler-Heisenberg gravity. Nonlinear
electromagnetic fields lead to rich thermodynamic phase structures and
significantly affect the QNMs of massless scalar fields. By analyzing the QNMs
spectrum, we find that the transition point marking the disappearance of
divergence in the QNMs slope parameter $K$ aligns with the change of the
thermodynamic phase structure described by the heat capacity, within the bounds
of computational uncertainty. This precise matching holds under variations of
curvature parameters and charge. Furthermore, we show that larger angular
quantum number $l$ diminishes this correspondence, while higher overtone number
$n$ restores it beyond a threshold. These findings demonstrate that
thermodynamic phase transitions of black holes carry embedded dynamical
information, uncovering a fundamental link between black hole thermodynamic and
dynamical properties.

</details>


### [7] [Aspects of 4d $\mathcal{N}=1$ $ADE$ gauge theories from M-theory: decomposition, automorphisms, and generalised symmetries](https://arxiv.org/abs/2508.00564)
*Osama Khlaif,Marwan Najjar*

Main category: hep-th

TL;DR: This paper explores the decomposition of 4d N=1 gauge theories with specific Lie algebras via M-theory geometric engineering, revealing new structures through automorphisms and analyzing their symmetries and topological features.


<details>
  <summary>Details</summary>
Motivation: To understand the decomposition structure of 4d N=1 gauge theories with su(N), so(2N), and e6 algebras in the context of M-theory and finite group actions on geometric spaces.

Method: Using M-theory geometric engineering and quotienting the Bryant-Salamon spin bundle over the 3-sphere by special finite subgroups, the authors analyze gauge theory breaking via inner and outer automorphisms, and study p-form and (-1)-form symmetries, SymTFTs, and topological structures.

Result: The paper shows that outer automorphisms extend decomposition to so(2N+1), sp(2N), f4, and g2 gauge algebras, derives SymTFTs and symmetry operators from M-theory, and identifies modified instanton sums and higher 4-group structures.

Conclusion: The decomposition of 4d N=1 gauge theories is deeply tied to M-theoretic geometry, with automorphisms playing a key role in extending structures to non-simply-laced algebras, and symmetries and topological sectors can be fully derived from M-theory.

Abstract: We study the decomposition of 4d $\mathcal{N}=1$ gauge theories with Lie
algebras of type $\mathfrak{su}(N)$, $\mathfrak{so}(2N)$, and
$\mathfrak{e}_{6}$, realized via M-theory geometric engineering. These
theories, together with their novel decomposition structure, arise from
quotienting the Bryant--Salamon spin bundle over the 3-sphere by special finite
subgroups acting simultaneously on both the fiber and base. We show that these
gauge theories admit both inner and outer automorphisms, enabling sequences of
gauge theory breaking. In particular, outer automorphisms extend the
decomposition structure to theories with $\mathfrak{so}(2N+1)$,
$\mathfrak{sp}(2N)$, $\mathfrak{f}_{4}$, and $\mathfrak{g}_{2}$ gauge algebras.
For these theories, including both simply-laced and non-simply-laced cases, we
analyze their $p$-form symmetries, including $(-1)$-form symmetries, derive the
corresponding SymTFTs, and identify the M-theoretic origin of their symmetry
topological operators and defects. Finally, we demonstrate that these gauge
theories exhibit modified instanton sums and higher 4-group structures, and we
derive the associated topological sector directly from M-theory.

</details>


### [8] [Higher spin fields and the field strength multicopy](https://arxiv.org/abs/2508.00711)
*Graham R. Brown,Bill Spence*

Main category: hep-th

TL;DR: The paper explores the generalization of the Weyl double copy to higher spin 'multi-copies', linking higher spin field strengths to powers of the Maxwell tensor in Kerr-Schild spacetimes, with insights from spinor formalisms and applications in various dimensions and anti-de Sitter backgrounds.


<details>
  <summary>Details</summary>
Motivation: To extend the Weyl double copy framework to higher spin fields and explore its implications across different spacetime dimensions and backgrounds, particularly using spinor methods and vector superspace formalisms.

Method: The authors use Kerr-Schild coordinates and spinor descriptions to relate higher spin field strengths to powers of the Maxwell tensor, analyze the role of Fronsdal equations, and examine formulations in vector superspace for both higher spin and continuous spin representations, including in anti-de Sitter space.

Result: The multi-copy construction is shown to be particularly clear in four dimensions using spinors; higher-dimensional extensions reveal new features tied to the little group; the Kerr-Schild higher spin fields fit naturally into a simple vector superspace expression when the continuous spin parameter is zero; and a modified covariant derivative clarifies the Segal formalism in AdS.

Conclusion: The Weyl double copy can be generalized to higher spins in a consistent way using spinor and Kerr-Schild frameworks, but challenges remain in formulating a full continuous spin theory.

Abstract: We discuss the generalisation of the Weyl double copy to higher spin
"multi-copies", showing how the natural linearised higher spin field strengths
can be related to sums of powers of the Maxwell tensor. The tracelessness of
the field strength involves the appropriate Fronsdal equations of motion for
the higher spin field. We work with spacetimes admitting Kerr-Schild
coordinates and give a number of examples in different dimensions. We note that
the multi-copy is particularly transparent in four dimensions if one uses
spinor descriptions of the fields, relating this to the Penrose transform. The
higher-dimensional spinor multicopy is also explored and reveals some
interesting new features arising from the little group based identification of
higher spin field strengths and Maxwell tensor types. We then turn to the
vector superspace formalism describing higher spin and `continuous' spin
representations given by Schuster and Toro, based on symmetric tensor fields.
Here the Kerr-Schild higher spin fields we have used earlier naturally package
into a simple expression involving an arbitrary function, when the continuous
spin scale $\rho$ is set to zero. Further, we discuss the case of an anti-de
Sitter background, where there is also a vector space formalism given by Segal
and we clarify this approach using a different definition of the covariant
derivative. We give a general solution of Kerr-Schild type and finally we
describe some of the obstacles to a continuous spin formulation.

</details>


### [9] [Gauge symmetry and radiatively induced terms in dimension-5 non-minimal Lorentz-violating QED](https://arxiv.org/abs/2508.00801)
*A. P. B. Scarpelli,A. R. Vieira*

Main category: hep-th

TL;DR: This paper investigates gauge invariance in a non-minimal dimension-5 Lorentz-violating QED, showing that the conditions for gauge symmetry match those of standard QED, and demonstrates that a Lorentz-violating term in the fermion sector can radiatively induce a similar term in the photon sector.


<details>
  <summary>Details</summary>
Motivation: To understand the conditions for gauge invariance in a non-minimal Lorentz-violating extension of QED and to explore radiative inductions between fermion and photon sectors.

Method: Derivation of gauge invariance conditions and computation of two- and three-point functions at one-loop level; verification of gauge Ward identities.

Result: The conditions for gauge symmetry in the non-minimal Lorentz-violating QED are the same as in standard QED. The non-minimal Lorentz-violating $a^{(5)}_F$-term in the fermion sector induces a corresponding term in the photon sector radiatively.

Conclusion: Gauge invariance in this non-minimal framework is preserved under the same conditions as usual QED, and cross-sector radiative inductions of Lorentz-violating terms are possible.

Abstract: In this work, we derive the conditions that assure gauge invariance of a
non-minimal dimension-5 Lorentz-violating QED. The two and three point
functions at one-loop are computed. The gauge Ward identities are checked and
the conditions to assure gauge symmetry of this non-minimal framework is found
to be the same of the usual QED. Induced terms are also investigated and it is
shown that the non-minimal Lorentz-violating $a^{(5)}_F$-term of the fermion
sector can induce radiatively a non-minimal Lorentz-violating term in the
photon sector.

</details>


### [10] [Proper-time functional renormalization in $O(N)$ scalar models coupled to gravity](https://arxiv.org/abs/2508.00807)
*Alfio Bonanno,Emiliano Glaviano,Gian Paolo Vacca*

Main category: hep-th

TL;DR: The paper investigates the functional Wilsonian renormalization group with a proper time regulator to study scaling solutions and critical properties of an O(N)-invariant scalar field coupled to gravity in 3D and 4D, comparing results with those from the effective average action approach.


<details>
  <summary>Details</summary>
Motivation: To test the functional Wilsonian renormalization group framework with a proper time regulator and compare its predictions for scaling solutions and critical exponents with those obtained using the effective average action method.

Method: Uses the functional Wilsonian renormalization group with proper time regulator, applying the same background-fluctuation splitting and gauge fixing as in previous studies based on the effective average action; employs similar truncations of the effective action.

Result: Most results for scaling solutions and critical exponents are consistent with previous findings both qualitatively and quantitatively; however, some differences appear at finite N and in the large N limit, particularly in 'improved' schemes.

Conclusion: The functional Wilsonian renormalization group with proper time regulator is a reliable tool for studying critical phenomena in scalar-gravity systems, confirming prior results overall, though scheme-dependent discrepancies suggest subtleties in the large N and improved truncation limits.

Abstract: We focus on the use of the functional Wilsonian renormalization group
framework characterized by a proper time regulator and test its use in the
search of the scaling solutions and the critical properties of an
O(N)-invariant scalar field multiplet coupled to gravity in d=4 and d=3
dimensions. We employ the same background-fluctuation splitting and gauge
fixing procedure, already adopted in a previous study based, instead, on the
effective average action framework and a similar truncation of the effective
action. Our main goal is to compare the results for the scaling solutions and
some of the associated critical exponents. In this analysis, performed in a
different framework, most of the picture previously uncovered is confirmed both
at qualitative and quantitative level. There are, neverthelss, few differences
both at finite N and in its large value limit, depending also on the schemes
which in both frameworks are called 'improved'

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [11] [A Variant of Non-uniform Cylindrical Algebraic Decomposition for Real Quantifier Elimination](https://arxiv.org/abs/2508.00505)
*Jasper Nalbach,Erika Ábrahám*

Main category: cs.SC

TL;DR: This paper introduces a new variant of Non-uniform CAD (NuCAD) for real quantifier elimination and SMT solving, provides its implementation, and evaluates it experimentally against Cylindrical Algebraic Covering (CAlC).


<details>
  <summary>Details</summary>
Motivation: NuCAD was previously limited to quantifier elimination with no complete implementation; this work extends it to both quantifier elimination and SMT solving, addressing a gap in practical real-algebraic problem solving.

Method: The authors develop a novel variant of NuCAD, implement it, and experimentally compare its performance with CAlC, another modern adaptation of CAD.

Result: A complete implementation of NuCAD is achieved, and experimental comparisons with CAlC are provided, demonstrating its effectiveness in both quantifier elimination and SMT solving contexts.

Conclusion: The proposed NuCAD variant is a viable and practical method for real-algebraic problems, bridging the gap between theoretical design and implementation in SMT solvers and quantifier elimination tools.

Abstract: The Cylindrical Algebraic Decomposition (CAD) method is currently the only
complete algorithm used in practice for solving real-algebraic problems. To
ameliorate its doubly-exponential complexity, different exploration-guided
adaptations try to avoid some of the computations. The first such adaptation
named NLSAT was followed by Non-uniform CAD (NuCAD) and the Cylindrical
Algebraic Covering (CAlC). Both NLSAT and CAlC have been developed and
implemented in SMT solvers for satisfiability checking, and CAlC was recently
also adapted for quantifier elimination. However, NuCAD was designed for
quantifier elimination only, and no complete implementation existed before this
work.
  In this paper, we present a novel variant of NuCAD for both real quantifier
elimination and SMT solving, provide an implementation, and evaluate the method
by experimentally comparing it to CAlC.

</details>


### [12] [Projective Delineability for Single Cell Construction](https://arxiv.org/abs/2508.00512)
*Jasper Nalbach,Lucas Michel,Erika Ábrahám,Christopher W. Brown,James H. Davenport,Matthew England,Pierre Mathonet,Naïm Zénaïdi*

Main category: cs.SC

TL;DR: This paper adapts single cell construction in cylindrical algebraic decomposition (CAD) to exploit projective delineability, reducing computational effort while maintaining completeness for solving real algebra problems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to reduce the high computational cost of CAD, which has doubly exponential complexity, by leveraging a weaker but more efficient condition called projective delineability.

Method: The paper adapts the single cell construction paradigm used in CAD-based algorithms (e.g., NLSAT, NuCAD, CAlC) to incorporate projective delineability, which requires fewer computations than classical delineability.

Result: The adapted method reduces computational effort in single cell construction, and experimental results demonstrate its effectiveness.

Conclusion: Projective delineability can be effectively integrated into single cell CAD methods, offering computational advantages while preserving correctness and completeness.

Abstract: The cylindrical algebraic decomposition (CAD) is the only complete method
used in practice for solving problems like quantifier elimination or SMT
solving related to real algebra, despite its doubly exponential complexity.
Recent exploration-guided algorithms like NLSAT, NuCAD, and CAlC rely on CAD
technology but reduce the computational effort heuristically. Single cell
construction is a paradigm that is used in each of these algorithms.
  The central property on which the CAD algorithm is based is called
delineability. Recently, we introduced a weaker notion called projective
delineability which can require fewer computations to guarantee, but needs to
be applied carefully. This paper adapts the single cell construction for
exploiting projective delineability and reports on experimental results.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [13] [Reconstructing Transition GPDs for Delta(1232) from Helicity Amplitude A_1/2(Q^2) via Dipole Fits and Impact Parameter Analysis](https://arxiv.org/abs/2508.00018)
*Ralph M. Marinaro III*

Main category: hep-ph

TL;DR: A modular, data-driven reconstruction of the transition generalized parton distribution H_T(x,t) for the Delta(1232) is presented, using helicity amplitude data and dipole fits to model a separable GPD that links amplitude behavior to transverse spatial structure.


<details>
  <summary>Details</summary>
Motivation: To develop a physically interpretable and reproducible framework for reconstructing transition GPDs using empirical data, enabling insight into the spatial structure of the Delta(1232) resonance.

Method: The method involves digitizing helicity amplitude data, performing dipole fits to A_1/2(Q^2), extracting a Sachs-like form factor F(t), and constructing a separable GPD model H_T(x, t) = h(x)F(t) with h(x) as a Beta-like distribution. A 2D Fourier transform is applied to obtain transverse spatial distributions q(x,b), with spatial features analyzed via statistical moments.

Result: The model satisfies the GPD sum rule and enables visualization of transverse spatial distributions. Key spatial characteristics—such as mean radius, skewness, and kurtosis—are quantified, revealing how longitudinal momentum shaping influences transverse localization.

Conclusion: The proposed framework provides a robust, reproducible, and extendable approach to mapping transition GPDs, offering a direct link between experimental amplitude data and spatial partonic structure, applicable to other hadronic transition processes.

Abstract: We present a modular reconstruction of the transition generalized parton
distribution (GPD) H_T(x,t) for the Delta(1232) resonance, based on digitized
helicity amplitude data and dipole fits to A_1/2(Q^2). From the fitted
amplitude, we extract a Sachs-like form factor F(t) and define a separable GPD
model H_T(x, t) = h(x)F(t), with h(x) modeled as a normalized Beta-like
profile. This factorized ansatz satisfies the GPD sum rule and enables a direct
two-dimensional Fourier transform to construct transverse spatial distributions
q(x,b). We analyze how longitudinal shaping modulates transverse localization,
and quantify spatial features using statistical diagnostics including mean
radius, skewness, and kurtosis. The framework is reproducible, data-driven, and
applicable to other transition channels, providing a physically interpretable
map from amplitude behavior to spatial structure.

</details>


### [14] [Dark wounds on icy moons: Ganymede's subsurface ocean as a dark matter detector](https://arxiv.org/abs/2508.00054)
*William DeRocco*

Main category: hep-ph

TL;DR: This paper explores the potential for detecting macroscopic dark matter impacts on Ganymede, leveraging its ancient surface and unique composition. Analytic estimates and simulations show that dark matter collisions could penetrate the ice layer, exposing subsurface material distinguishable from surface ice, offering a unique signature to differentiate from asteroid impacts. Upcoming missions like Europa Clipper and JUICE may be able to detect these signatures, enabling searches for both life and dark matter in the Jovian system.


<details>
  <summary>Details</summary>
Motivation: Macroscopic dark matter in the mass range of 10^11 to 10^17 grams is poorly constrained, and its detection requires novel observational strategies. Collisions with planetary bodies like Ganymede could leave long-lasting surface features, offering a new pathway for indirect detection.

Method: The authors use analytic modeling to estimate the penetration depth and effects of dark matter impacts on Ganymede's ice shell, followed by numerical simulations using the iSALE multi-material impact code to validate these estimates.

Result: Analytic and simulation results show that dark matter in a significant parameter space can penetrate Ganymede's conductive ice layer, ejecting compositionally distinct subsurface material. This creates observable surface anomalies that differ from those caused by asteroid impacts.

Conclusion: Ganymede is a promising target for detecting macroscopic dark matter. Observations from upcoming missions such as Europa Clipper and JUICE could potentially identify impact signatures of dark matter, opening a new avenue for dark matter searches in the solar system.

Abstract: Dark matter in the form of macroscopic composites is largely unconstrained at
masses of $\sim 10^{11}- 10^{17}$ g. In this mass range, dark matter may
collide with planetary bodies, depositing an immense amount of energy and
leaving dramatic surface features that remain detectable on geological
timescales. In this paper, we show that Ganymede, the largest Jovian moon,
provides a prime target to search for dark matter impacts due to its
differentiated composition and Gyr-old surface. We study the effects of dark
matter collisions with Ganymede first with analytic estimates, finding that in
a large region of parameter space, dark matter punches through Ganymede's
conductive ice sheet, liberating sub-surface material. This sub-surface
material may be compositionally different from the surface ice, providing a key
observable with which to discriminate asteroid impacts from those caused by
dark matter. We confirm our analytic estimates with dedicated simulations of
dark matter impacts using iSALE, a multi-material impact code. We then discuss
potential detection prospects with two missions currently en route to the
Jovian system, Europa Clipper and JUICE, finding that these missions may have
the ability not only to identify signs of life on the Galilean moons, but signs
of dark matter as well.

</details>


### [15] [Anomaly detection with spiking neural networks for LHC physics](https://arxiv.org/abs/2508.00063)
*Barry M. Dillon,Jim Harkin,Aqib Javed*

Main category: hep-ph

TL;DR: This paper explores the use of Spiking Neural Network (SNN) based AutoEncoders for anomaly detection at the LHC, showing they are competitive with conventional AutoEncoders while being well-suited for low-latency, hardware-efficient deployment.


<details>
  <summary>Details</summary>
Motivation: To develop efficient anomaly detection methods for the LHC that operate under strict latency and computational constraints, potentially enabling the discovery of new physics at the trigger level.

Method: Design and evaluation of a simple SNN AutoEncoder architecture using the CMS ADC2021 dataset, leveraging neuromorphic computing properties for real-time, low-power inference.

Result: SNN AutoEncoders perform competitively with conventional AutoEncoders across all tested signal models in LHC anomaly detection.

Conclusion: SNN-based AutoEncoders are a viable and efficient option for anomaly detection in high-energy physics, especially for deployment in resource-constrained environments like FPGAs and future neuromorphic hardware.

Abstract: Anomaly detection offers a promising strategy for discovering new physics at
the Large Hadron Collider (LHC). This paper investigates AutoEncoders built
using neuromorphic Spiking Neural Networks (SNNs) for this purpose. One key
application is at the trigger level, where anomaly detection tools could
capture signals that would otherwise be discarded by conventional selection
cuts. These systems must operate under strict latency and computational
constraints. SNNs are inherently well-suited for low-latency, low-memory,
real-time inference, particularly on Field-Programmable Gate Arrays (FPGAs).
Further gains are expected with the rapid progress in dedicated neuromorphic
hardware development. Using the CMS ADC2021 dataset, we design and evaluate a
simple SNN AutoEncoder architecture. Our results show that the SNN AutoEncoders
are competitive with conventional AutoEncoders for LHC anomaly detection across
all signal models.

</details>


### [16] [Worldline Modeling of Ultra-Intense Lasers for N-photon Scattering Processes](https://arxiv.org/abs/2508.00105)
*Ivan Ahumada,Patrick Copinger,James P. Edwards,Karthik Rajeev*

Main category: hep-ph

TL;DR: The paper presents a first-quantized path integral approach to strong-field QED, enabling non-perturbative treatment of ultra-intense lasers as background fields and deriving compact Master Formulae for N-photon scattering processes for scalars and spinors across various field configurations.


<details>
  <summary>Details</summary>
Motivation: Ultra-intense lasers require modeling beyond standard perturbative methods; existing diagrammatic approaches fail to fully capture strong-field effects non-perturbatively.

Method: The authors use a first-quantized path integral representation in strong-field QED, treating the laser as a non-perturbative background field, and develop an all-multiplicity framework for N-photon scattering processes for both complex scalars and spinors.

Result: Compact Master Formulae are derived for tree-level N-photon scattering in various background fields, including plane waves, impulsive PP-waves, non-null fields, and constant-crossed fields, with low-energy external photons.

Conclusion: The path integral approach provides a powerful non-perturbative framework for strong-field QED, enabling systematic and compact descriptions of multi-photon processes in diverse intense laser backgrounds.

Abstract: The modeling of present and future ultra-intense lasers demands techniques
that go beyond the standard diagrammatic approach to non-perturbatively fully
capture the effects of strong fields. We illustrate the first-quantized path
integral representation for strong-field quantum electrodynamics as a means of
accessing the laser being treated as a background field, which is treated
without recourse to perturbation theory. We examine an all-multiplicity
construction for $N-$photon scattering processes for complex scalars and
spinors, showing compact Master Formulae for tree-level scattering. Several
background fields are considering including: plane waves, impulsive PP-waves,
non-null fields, and homogeneous fields (constant-crossed fields) with
low-energy external photons.

</details>


### [17] [Distinguishing between Dirac and Majorana neutrinos at FASER](https://arxiv.org/abs/2508.00170)
*ShivaSankar K. A.,Alakabha Datta,Danny Marfatia*

Main category: hep-ph

TL;DR: FASER can distinguish between Dirac and Majorana right-handed neutrinos using spatial distributions of electron-positron pairs from three-body decays, achieving up to 3σ discrimination for ~0.1 GeV RHNs via SMNEFT interactions.


<details>
  <summary>Details</summary>
Motivation: Determining whether right-handed neutrinos are Dirac or Majorana particles has profound implications for lepton number conservation and the nature of neutrinos; this distinction is a key question in neutrino physics.

Method: Used Monte Carlo simulations and chi-squared analysis of kinematic and angular distributions of decay products in the RHN rest frame, focusing on RHNs produced from meson decays (B, D, K, pi) at LHC and detected via three-body decays in FASER.

Result: Significant differences in spatial distributions of electron-positron pairs at FASER are found between Dirac and Majorana RHNs; discrimination at 3σ level is achievable for certain operator combinations and RHN masses around 0.1 GeV.

Conclusion: Spatial observables in FASER provide a robust probe to determine the Dirac or Majorana nature of right-handed neutrinos within the SMNEFT framework.

Abstract: Some of the simplest models for the origin of neutrino mass involve
right-handed neutrinos (RHNs), which could be either Dirac or Majorana
particles - a distinction that has profound implications for lepton number
conservation and the fundamental nature of neutrinos. We investigate the
potential of the FASER experiment to distinguish between these two
possibilities using signatures predicted by the Standard Model Neutrino
Effective Field Theory (SMNEFT), where RHNs interact with Standard Model
particles through higher-dimensional operators. We focus on RHNs produced via
$B$, $D$, $K$, and $\pi$ meson decays at the Large Hadron Collider and their
subsequent three-body decays within the FASER detector. The kinematic and
angular distributions of the decay products in the RHN rest frame differ
significantly for Dirac and Majorana RHNs, and these differences manifest as
distinct spatial distributions of electron-positron pairs at FASER. Using Monte
Carlo simulations and a $\chi^2$ analysis, we demonstrate that these spatial
observables provide a robust experimental probe for determining the Dirac or
Majorana nature of RHNs. For select production and decay operator combinations
and RHN masses around 0.1 GeV, FASER can achieve discrimination at the
$3\sigma$ level.

</details>


### [18] [Variational Neural Network Approach to QFT in the Field Basis](https://arxiv.org/abs/2508.00173)
*Kevin Braga,Nobuo Sato,Adam P. Szczepaniak*

Main category: hep-ph

TL;DR: A variational neural network approach is used to solve the free Klein-Gordon model in momentum space, enabling direct comparison with exact results and demonstrating the effectiveness of momentum-space field basis for benchmarking.


<details>
  <summary>Details</summary>
Motivation: To systematically benchmark neural-network-based variational methods for quantum field theories using the analytically solvable Klein-Gordon model in momentum space, which has been previously underexplored.

Method: Represent the ground-state wavefunctional as a neural network on discretized field configurations and train it by minimizing the Hamiltonian expectation value in momentum space.

Result: Accurate reproduction of key observables such as ground-state energy, two-point correlators, field expectation values, and wavefunctional structure, with quantitative agreement with exact analytic results.

Conclusion: Momentum space is well-suited for benchmarking neural network approaches to quantum field theories, and this framework provides a solid foundation for extending to interacting models and position-space formulations.

Abstract: We present a variational neural network approach for solving quantum field
theories in the field basis, focusing on the free Klein-Gordon model formulated
in momentum space. While recent studies have explored neural-network-based
variational methods for scalar field theory in position space, a systematic
benchmark of the analytically solvable Klein-Gordon ground state --
particularly in the momentum-space field basis -- has been lacking. In this
work, we represent the ground-state wavefunctional as a neural network defined
on a discretized set of field configurations and train it by minimizing the
Hamiltonian expectation value. This framework enables direct comparison to
exact analytic results for a range of key observables, including the
ground-state energy, two-point correlators, expectation value of the field, and
the structure of the learned wavefunctional itself. Our results provide
quantitative diagnostics of accuracy and demonstrate the suitability of
momentum space for benchmarking neural network approaches, while establishing a
foundation for future extensions to interacting models and position-space
formulations.

</details>


### [19] [Analytic Solution for the Helicity Evolution Equations at Small $x$ and Large $N_c\&N_f$](https://arxiv.org/abs/2508.00195)
*Jeremy Borden,Yuri V. Kovchegov*

Main category: hep-ph

TL;DR: An exact analytic solution is constructed for revised small-x helicity evolution equations including quark-gluon transitions in the large-Nc&Nf limit, enabling analytic expressions for helicity PDFs, g1 structure function, and polarized DGLAP anomalous dimensions, with resummation of alpha_s ln^2(1/x) terms; the small-x growth is characterized by an intercept alpha_h determined numerically, and asymptotic ratios of gluon to quark helicity are computed, showing consistency with existing calculations but slight disagreement with infrared evolution equation predictions.


<details>
  <summary>Details</summary>
Motivation: To improve the understanding of helicity evolution at small-x by incorporating previously neglected quark-to-gluon and gluon-to-quark transition contributions in the evolution equations, allowing for a more complete and accurate description of polarized parton dynamics in the high-energy (small-x) regime.

Method: The analysis is performed in the large-Nc and large-Nf limit using double-logarithmic resummation of alpha_s ln^2(1/x) terms; exact analytic solutions are derived for the helicity evolution equations, and results are expressed via double-inverse Laplace transforms; analytic expressions for polarized DGLAP anomalous dimensions are obtained by Mellin transform techniques, and the small-x asymptotic behavior is studied through numerical solution of an algebraic equation for the intercept alpha_h.

Result: Derived analytic expressions for flavor-singlet quark and gluon helicity PDFs, the g1 structure function, and four polarized DGLAP anomalous dimensions; found power-law growth of helicity distributions as (1/x)^alpha_h with alpha_h determined numerically; computed asymptotic ratio of gluon to quark helicity PDFs; confirmed consistency with known DGLAP results and identified slight discrepancy with infrared evolution equation framework.

Conclusion: The inclusion of quark-gluon transition terms in the small-x helicity evolution equations leads to a consistent and predictive analytic framework that accurately captures the small-x helicity structure, providing new insights into polarized parton dynamics, though minor discrepancies with alternative theoretical approaches suggest room for further refinement.

Abstract: We construct an exact analytic solution of the revised small-$x$ helicity
evolution equations, where the contributions of the quark-to-gluon and
gluon-to-quark transition operators were newly included. These evolution
equations are written in the large-$N_c\&N_f$ limit and are double-logarithmic,
resumming powers of $\alpha_s\ln^2(1/x)$. Here $N_c$ and $N_f$ are the numbers
of quark colors and flavors, while $\alpha_s$ is the strong coupling constant
and $x$ is the Bjorken-$x$ variable. Using our solution, we obtain analytic
expressions for the flavor singlet quark and gluon helicity parton distribution
functions (PDFs) and for the $g_1$ structure function as double-inverse Laplace
transforms. We also extract analytic expressions for the four DGLAP polarized
anomalous dimensions $\Delta \gamma_{qq}, \Delta \gamma_{qG}, \Delta
\gamma_{Gq}$, and $\Delta \gamma_{GG}$: these expressions resum powers of
$\alpha_s/\omega^2$ to all orders at large-$N_c\&N_f$ (with $\omega$ the Mellin
moment variable). We extract the leading small-$x$ growth of the helicity
distributions, \begin{align} \Delta\Sigma(x,Q^2) \sim \Delta G(x,Q^2)\sim
g_1(x,Q^2) \sim \left(\frac{1}{x}\right)^{\alpha_h}, \end{align} where the
intercept $\alpha_h$ satisfies an algebraic equation. We determine $\alpha_h$
numerically for various values of $N_c$ and $N_f$. We further obtain the
explicit asymptotic expressions for the helicity distributions, which yield
numerical values for the ratio of the gluon helicity PDF to the flavor singlet
quark helicity PDF in the small-$x$ asymptotic limit (for different $N_f/N_c$).
We find that all our predictions for polarized DGLAP anomalous dimensions are
fully consistent with the existing finite-order calculations. Similar to the
large-$N_c$ case, our intercept $\alpha_h$ exhibits a very slight disagreement
with the predictions made within the infrared evolution equations framework.

</details>


### [20] [Neutrino magnetic moment in the doublet-singlet Leptoquark model](https://arxiv.org/abs/2508.00226)
*Ricardo Sánchez-Vélez*

Main category: hep-ph

TL;DR: The paper studies the neutrino transition magnetic moment in a Standard Model extension with two Leptoquarks, finding sizable contributions, especially with bottom quarks in the loop, and shows compatibility with recent experimental constraints and anomalies in B-meson decays.


<details>
  <summary>Details</summary>
Motivation: To investigate the neutrino transition magnetic moment in a simple extension of the Standard Model involving Leptoquarks, and to explore its implications for current experimental anomalies and constraints.

Method: A theoretical model with two Leptoquarks (S1 and R2) is constructed; loop contributions to the neutrino transition magnetic moment are calculated, and parameter space is analyzed using constraints from (g-2)μ, Br(τ → μγ), B-meson decay anomalies (RD(*)), and direct detection limits from XENONnT and LZ.

Result: The model generates a sizable neutrino transition magnetic moment, particularly enhanced by bottom quark loops; large Leptoquark Yukawa couplings are still allowed due to parameter degeneracy, and the model remains consistent with RD(*) anomalies and dark matter experiment limits.

Conclusion: The Leptoquark extension provides a viable explanation for enhanced neutrino transition moments and B-decay anomalies while remaining compatible with current experimental bounds, including muon g-2 and direct detection searches.

Abstract: The neutrino transition magnetic moment $\mu_{\nu_{\alpha \beta}}$ is studied
in a simple extension of the Standard Model. This extension incorporates two
scalar Leptoquarks $S_1$ and $\widetilde{R}_2$ with quantum numbers
$(\bar{3},1,1/3)$ and $(3,2,1/6)$ respectively. It is found that these
Leptoquarks generate a sizable transition magnetic moment, particularly when
the quark bottom is running in the loop. For our analysis of the parameter
space, we include the latest measurement of the muon magnetic moment and
combine it with the experimental constraint on the branching ratio Br$(\tau \to
\mu \gamma)$. We found that, despite the recent agreement on the $(g-2)_\mu$
value, large values for Leptoquark Yukawa couplings are allowed due to a
degeneracy in the parameters. Additionally, we explore how the Leptoquark model
address the anomalies observed in the ratios of semileptonic $B$ mesons decays,
$R_{D^{(*)}}$. We determine that the restrictions derived from our analysis are
consistent with the most recent experimental limits reported by the XENONnT and
LUX-ZEPLIN collaborations. This conclusion is based on our evaluation of the
transition magnetic moment from muon neutrino to tau neutrino, focusing on the
allowed region for the Leptoquark Yukawa couplings.

</details>


### [21] [Jet Image Generation in High Energy Physics Using Diffusion Models](https://arxiv.org/abs/2508.00250)
*Victor D. Martinez,Vidya Manian,Sudhir Malik*

Main category: hep-ph

TL;DR: This paper introduces the first application of diffusion models to generate jet images from proton-proton collisions at the LHC, comparing score-based and consistency models in image space for improved fidelity and efficiency.


<details>
  <summary>Details</summary>
Motivation: To improve the generation of jet images for high energy physics simulations by leveraging diffusion models directly in image space, avoiding limitations of latent distribution-based methods.

Method: Jet kinematic data from the JetNet dataset is converted into 2D images; score-based diffusion and consistency models are trained to generate class-conditional jet images, with evaluation based on metrics like FID.

Result: Consistency models outperform score-based diffusion models in generation fidelity and stability, achieving better Fréchet Inception Distance scores and improved computational efficiency.

Conclusion: Diffusion models, particularly consistency models, are effective for high-fidelity jet image generation, offering valuable tools for future HEP research and simulation.

Abstract: This article presents, for the first time, the application of diffusion
models for generating jet images corresponding to proton-proton collision
events at the Large Hadron Collider (LHC). The kinematic variables of quark,
gluon, W-boson, Z-boson, and top quark jets from the JetNet simulation dataset
are mapped to two-dimensional image representations. Diffusion models are
trained on these images to learn the spatial distribution of jet constituents.
We compare the performance of score-based diffusion models and consistency
models in accurately generating class-conditional jet images. Unlike approaches
based on latent distributions, our method operates directly in image space. The
fidelity of the generated images is evaluated using several metrics, including
the Fr\'echet Inception Distance (FID), which demonstrates that consistency
models achieve higher fidelity and generation stability compared to score-based
diffusion models. These advancements offer significant improvements in
computational efficiency and generation accuracy, providing valuable tools for
High Energy Physics (HEP) research.

</details>


### [22] [On the gravitational waves from super massive RHNs produced at preheating](https://arxiv.org/abs/2508.00315)
*Shinya Kanemura,Kunio Kaneta,Dibyendu Nanda*

Main category: hep-ph

TL;DR: The paper explores how supermassive particles, like right-handed neutrinos, can be efficiently produced after inflation via non-perturbative mechanisms such as parametric resonance, even when their masses exceed the inflaton mass. These particles emit gravitons through bremsstrahlung during decay, generating a stochastic gravitational wave background. This mechanism is studied within \alpha-attractor inflation models, where the resulting gravitational wave spectrum provides indirect evidence of heavy particles and high-scale physics beyond the Standard Model.


<details>
  <summary>Details</summary>
Motivation: To understand the post-inflationary production of supermassive particles and their impact on the universe's thermal history, particularly seeking observational signatures of otherwise inaccessible high-energy physics through gravitational waves.

Method: The authors analyze non-perturbative particle production via parametric resonance in \alpha-attractor inflation models, focusing on right-handed neutrinos coupled to the inflaton. They study graviton emission through bremsstrahlung during RHN decay into Standard Model particles, enabled by minimal gravitational coupling, and compute the resulting stochastic gravitational wave background.

Result: The decay of right-handed neutrinos produces a detectable stochastic gravitational wave background via bremsstrahlung. The resulting GW spectrum carries imprints of the heavy particle sector and post-inflationary dynamics, with specific features depending on model parameters within the \alpha-attractor framework.

Conclusion: The study provides a viable mechanism to probe supermassive particles beyond the Standard Model through gravitational wave observations, offering a new window into high-scale physics and post-inflationary universe dynamics.

Abstract: The post-inflationary production of supermassive particles can have profound
implications for the thermal history of the universe and may leave observable
imprints in the gravitational wave (GW) background. In scenarios where the
inflaton couples predominantly to heavy fields, say right-handed neutrino
(RHN), non-perturbative mechanisms such as parametric resonance can lead to
their efficient production, even when their masses exceed the inflaton mass.
Once produced, the RHNs emit gravitons through bremsstrahlung as they decay
into the Standard Model (SM) particles via $N\rightarrow \ell + H$, enabled by
the unavoidable minimal coupling to gravity, sourcing a stochastic GW
background. We study this mechanism within the framework of $\alpha-$attractor
inflationary models, highlighting how the resulting GW spectrum carries
indirect imprints of the heavy sector and the post-inflationary dynamics. This
offers an observational window into otherwise inaccessible supermassive
particles and provides a powerful probe of high-scale physics beyond the SM.

</details>


### [23] [Analysis of the hadronic molecules $DK$, $D^*K$, $DK^*$ and their bottom analogs with QCD sum rules](https://arxiv.org/abs/2508.00402)
*Ze Zhou,Guo-Liang Yu,Zhi-Gang Wang,Jie Lu*

Main category: hep-ph

TL;DR: The study uses two-point QCD sum rules with color-singlet-color-singlet type currents to predict masses and pole residues of charm-strange and bottom analog tetraquark states with $J^P = 0^+$ and $1^+$. The predicted masses for $DK$, $D^*K$, and $DK^*$ states agree well with experimental candidates $D_{s0}(2317)$, $D_{s1}(2460)$, and $D_{s1}(2536)$. For bottom analogs, $BK$ and $B^*K$ masses are above threshold, while the $BK^*$ mass is below threshold, suggesting it could be a bound hadronic molecule.


<details>
  <summary>Details</summary>
Motivation: To investigate the nature of charm-strange and bottom analog tetraquark states as possible hadronic molecules using QCD sum rules, and to compare theoretical predictions with experimental observations.

Method: Two-point QCD sum rules are employed with color-singlet-color-singlet type interpolating currents. Vacuum condensates up to dimension 12 are included in the operator product expansion.

Result: Predicted masses: $DK$ ($2.322^{+0.066}_{-0.072}$ GeV), $D^*K$ ($2.457^{+0.064}_{-0.068}$ GeV), $DK^*$ ($2.538^{+0.059}_{-0.062}$ GeV) match well with $D_{s0}(2317)$, $D_{s1}(2460)$, and $D_{s1}(2536)$. Bottom analogs: $BK$ ($5.970^{+0.061}_{-0.064}$ GeV), $B^*K$ ($6.050^{+0.062}_{-0.064}$ GeV) are above threshold; $BK^*$ ($6.158^{+0.061}_{-0.063}$ GeV) is below threshold, indicating a possible bound state.

Conclusion: The results support interpreting $D_{s0}(2317)$, $D_{s1}(2460)$, and $D_{s1}(2536)$ as hadronic molecules. The $BK^*$ state is a promising candidate for a bound hadronic molecule due to its mass being below threshold, while $BK$ and $B^*K$ are likely not bound.

Abstract: In this work, we construct the color-singlet-color-singlet type currents to
study the masses and pole residues of charm-strange tetraquark states and their
bottom analogs with $J^P$ = $0^+$ and $1^+$ by using two-point QCD sum rules,
where the vacuum condensates are considered up to dimension 12. The predicted
masses for $DK$, $D^*K$ and $DK^*$ molecular states are $2.322_{ - 0.072}^{ +
0.066}$ GeV, $2.457_{ - 0.068}^{ + 0.064}$ GeV and $2.538_{ - 0.062}^{ +
0.059}$ GeV. These results are consistent well with the experimental data of
$D_{s0}(2317)$, $D_{s1}(2460)$ and ${D}_{s1}(2536)$, respectively. The
theoretical results for $BK$ and $B^*K$ molecular states are $5.970_{ -
0.064}^{ + 0.061}$ GeV and $6.050_{ - 0.064}^{ + 0.062}$ GeV which are all
higher than their own thresholds. Finally, the mass of hadronic molecule $BK^*$
is predicted to be $6.158_{ - 0.063}^{ + 0.061}$ GeV. This value is lower than
the threshold of $BK^*$, which implies that it may be a bound hadronic
molecular state.

</details>


### [24] [Thermoelectric figure of merit and the deconfinement phase transition](https://arxiv.org/abs/2508.00407)
*Kamaljeet Singh,Raghunath Sahoo*

Main category: hep-ph

TL;DR: This paper presents the first phenomenological study of the thermoelectric figure of merit (ZT) in hot QCD matter, analyzing its temperature dependence across the hadronic and quark-gluon plasma phases using model-based calculations, and revealing nontrivial behavior near the QCD phase transition that reflects changes in transport properties and degrees of freedom.


<details>
  <summary>Details</summary>
Motivation: To gain insight into the microscopic dynamics and redistribution of effective degrees of freedom in high-temperature QCD matter during the phase transition, using thermoelectric responses as a complementary probe to traditional transport studies.

Method: Model-based calculations of electrical conductivity, Seebeck coefficient, and thermal conductivity are used to analyze the temperature dependence of the thermoelectric figure of merit (ZT) in hot QCD matter.

Result: The thermoelectric figure of merit (ZT) shows nontrivial behavior near the QCD phase transition temperature, with characteristic features reflecting changes in transport properties and active degrees of freedom in the medium.

Conclusion: The study of ZT provides a new, complementary perspective on the evolution of QCD matter through the phase transition and may offer critical insights into the dynamics of the system in relativistic heavy-ion collisions.

Abstract: Thermoelectric phenomena are traditionally associated with the
interconversion of thermal and electrical energy in many-body systems. In the
context of high-temperature quantum chromodynamics (QCD) matter produced in
relativistic heavy-ion collisions, thermoelectric responses can provide insight
into the evolving microscopic dynamics and the redistribution of effective
degrees of freedom across the phase transition region. In this work, for the
first time, we present a phenomenological study of the thermoelectric figure of
merit (\( ZT \)) in hot QCD matter, with a particular focus on its behavior
across the hadronic and quark-gluon plasma phases. Using model-based
calculations for the electrical conductivity, Seebeck coefficient, and thermal
conductivity, we analyze the temperature dependence of \( ZT \) and identify
characteristic features near the QCD phase transition temperature. Our results
indicate that \( ZT \) exhibits nontrivial behavior near the transition region,
reflecting the changing transport properties and active degrees of freedom in
the medium. This phenomenological study of the thermoelectric figure of merit
provides a complementary perspective to traditional transport studies and may
provide critical insights for advancing the understanding of QCD matter through
the transition region.

</details>


### [25] [Rare few-body decays of the Standard Model Higgs boson](https://arxiv.org/abs/2508.00466)
*David d'Enterria,Van Dung Le*

Main category: hep-ph

TL;DR: A comprehensive survey of rare and exclusive Higgs boson decays with branching fractions below ~10^-5 is presented, including theoretical branching ratios for about 70 unobserved channels, experimental limits, and projected sensitivities at HL-LHC. The study includes 20 new channels involving photons, neutrinos, leptonium states, and radiative flavor-changing decays, aiding in constraining Yukawa couplings, probing new physics, and guiding future experimental efforts.


<details>
  <summary>Details</summary>
Motivation: To provide a systematic overview of rare Higgs decays that are currently unobserved but offer significant potential for probing SM parameters, constraining Yukawa couplings, testing QCD factorization, and searching for flavor-changing neutral currents or exotic decays beyond the SM.

Method: Theoretical calculations of branching fractions for approximately 70 rare Higgs decay channels are compiled, including 20 newly computed ones. The analysis includes decays into photons, neutrinos, leptonium states, and radiative flavor-changing processes. Current experimental limits and projected sensitivities at the HL-LHC are estimated based on proton-proton collision data.

Result: Comprehensive theoretical predictions for rare Higgs decays are provided, with updated branching fraction estimates. Twenty new decay channels are computed for the first time. Expected experimental reach at HL-LHC is outlined, identifying promising channels for future searches.

Conclusion: This survey serves as a valuable resource for prioritizing experimental and theoretical studies of rare Higgs decays, offering insights into fundamental Higgs properties and potential new physics through precision measurements at future colliders.

Abstract: We present a survey of rare and exclusive few-body decays of the standard
model (SM) Higgs boson, defined as those into two to four final particles with
branching fractions $\mathcal{B}\lesssim 10^{-5}$. Studies of such decays can
be exploited to constrain Yukawa couplings of quarks and leptons, probe
flavour-changing Higgs decays, estimate backgrounds for exotic Higgs decays
into beyond-SM particles, and/or confirm quantum chromodynamics factorization
with small nonperturbative corrections. We collect the theoretical
$\mathcal{B}$ values for about 70 unobserved Higgs rare decay channels,
indicating their current experimental limits, and estimating their expected
bounds in p-p collisions at the HL-LHC. Among those, we include 20 new decay
channels computed for the first time for ultrarare Higgs boson decays into
photons and/or neutrinos, radiative quark-flavour-changing exclusive decays,
and radiative decays into leptonium states. This survey can help guide and
prioritize upcoming experimental and theoretical studies of unobserved Higgs
boson decays.

</details>


### [26] [Improved Limits on Exotic Interactions Mediated by Axion-Like Particles Between Muons](https://arxiv.org/abs/2508.00504)
*L. Y. Wu,H. Yan*

Main category: hep-ph

TL;DR: Updated constraints on exotic muon interactions are derived based on the latest muon anomalous magnetic dipole moment measurement, where the discrepancy between experiment and theory is now $\Delta a_\\mu = (38 \\pm 63) \\times 10^{-11}$, indicating no significant deviation from the Standard Model.


<details>
  <summary>Details</summary>
Motivation: To constrain exotic interactions between muons mediated by new scalar or vector particles using the precise measurement of the muon anomalous magnetic dipole moment (AMDM), especially in light of recent experimental and theoretical advances that have reduced the tension between them.

Method: Using the latest experimental and Standard Model predicted values of the muon AMDM, the discrepancy $\\Delta a_\\mu$ is calculated and used to derive updated bounds on possible exotic interactions involving muons.

Result: The current discrepancy in the muon AMDM is $\\Delta a_\\mu = (38 \\pm 63) \\times 10^{-11}$, which is consistent with zero, leading to tighter constraints on new physics models involving scalar or vector mediators coupling to muons.

Conclusion: The absence of a significant anomaly in the muon AMDM implies stronger limits on exotic muon interactions, reducing the parameter space for new physics models that propose such couplings.

Abstract: The precise measurement of the muon anomalous magnetic dipole moment (AMDM)
$a_\mu$ provides an opportunity for constraining the exotic interactions
between muons mediated by new scalar or vector particles. Recent progress in
both experimental measurements and theoretical predictions of the muon AMDM has
reconciled the long-standing tension between them. Based on the latest result
for the muon AMDM, $\Delta a_\mu =a^{\rm exp}_\mu-a^{\rm SM}_\mu= (38 \pm 63)
\times 10^{-11}$, we derive updated constraints on exotic interactions between
muons.

</details>


### [27] [On multi-propagator angular integrals](https://arxiv.org/abs/2508.00693)
*Juliane Haug,Vladimir A. Smirnov,Fabian Wunder*

Main category: hep-ph

TL;DR: The paper introduces an Euler integral representation for multi-propagator angular integrals and develops recursive IBP and dimensional shift relations. It computes four-denominator angular integrals to finite order in ε and proposes a decomposition into branch integrals to reduce complexity, demonstrating the method by deriving all-order results for the massless three-denominator case with soft logarithm resummation.


<details>
  <summary>Details</summary>
Motivation: To extend loop-integral techniques to phase-space integrals without relying on reversed unitarity, enabling more efficient computation of multi-particle final states.

Method: Developed an Euler-type integral representation similar to Lee-Pomeransky, applied recursive IBP reduction and dimensional shift relations, used differential equations for master integrals, and introduced a decomposition into branch integrals to reduce scales.

Result: Computed angular integrals with four denominators to finite order in ε for arbitrary masses; reduced the number of scales in master integrals via branch integral decomposition; derived all-order ε results and soft logarithm resummation for the massless three-denominator case.

Conclusion: The proposed framework effectively transfers loop-integral methods to phase-space integrals, significantly simplifying calculations and enabling high-precision results for multi-particle processes.

Abstract: We study multi-propagator angular integrals, a class of phase-space integrals
relevant to processes with multiple observed final states and a test-bed for
transferring loop-integral technology to phase space integrals without reversed
unitarity. We present an Euler integral representation similar to
Lee-Pomeransky representation and explicitly describe a recursive IBP reduction
and dimensional shift relations for the general case of $n$ denominators. On
the level of master integrals, applying a differential equation approach, we
explicitly calculate the previously unknown angular integrals with four
denominators for any number of masses to finite order in $\varepsilon$.
Extending the idea of dimensional recurrence, we explore the decomposition of
angular integrals into branch integrals reducing the number of scales in the
master integrals from $(n+1)n/2$ to $n+1$. To showcase the potential of this
method, we calculate the massless three denominator integral to establish
all-order results in $\varepsilon$ including a resummation of soft logarithms.

</details>


### [28] [The SN 1987A Cooling Bound on Dark Matter Absorption in Electron Targets](https://arxiv.org/abs/2508.00725)
*Claudio Andrea Manzari,Jorge Martin Camalich,Jonas Spinner,Robert Ziegler*

Main category: hep-ph

TL;DR: New supernova cooling bounds on sub-MeV fermionic dark matter are presented, excluding parameter space relevant for direct detection experiments; similar exclusion holds even with light mediators when combining supernova and overproduction constraints.


<details>
  <summary>Details</summary>
Motivation: To constrain sub-MeV fermionic dark matter parameter space relevant for direct detection, especially where dark matter is absorbed by materials, and to assess complementarity with indirect searches and cosmological bounds.

Method: Analysis of SN 1987A cooling bounds applied to fermionic dark matter with effective electron couplings; extended to include sub-GeV light mediators, considering resonant production in supernovae and the early Universe.

Result: SN 1987A cooling bounds exclude the sensitivity regions of current and upcoming direct detection experiments for sub-MeV dark matter; even with light mediators, combined supernova and overproduction constraints rule out the entire relevant parameter space.

Conclusion: Supernova cooling and cosmological overproduction constraints strongly limit the viability of sub-MeV fermionic dark matter models with electron couplings, rendering them incompatible with direct detection prospects in the considered parameter space.

Abstract: We present new supernova (SN 1987A) cooling bounds on sub-MeV fermionic dark
matter with effective couplings to electrons. These bounds probe the parameter
space relevant for direct detection experiments in which dark matter can be
absorbed by the target material, showing strong complementarity with indirect
searches and constraints from dark matter overproduction. Crucially, our limits
exclude the projected sensitivity regions of current and upcoming direct
detection experiments. Since these conclusions are a priori not valid for light
mediators, we extend our analysis to this case. We show that sub-GeV mediators
can be produced resonantly both in supernova cores and in the early Universe,
altering the SN 1987A analysis for effective couplings. Still, a combination of
supernova cooling constraints and limits from dark matter overproduction
excludes the entire parameter space relevant for direct detection in this case.

</details>


### [29] [Non-Standard Neutrino Interactions at a Muon Collider Neutrino Detector](https://arxiv.org/abs/2508.00761)
*Felix Kling,Yang Ma,Krzysztof Mękała,Jürgen Reuter,Zahra Tabrizi*

Main category: hep-ph

TL;DR: Future multi-TeV muon colliders can serve as intense neutrino sources, enabling searches for non-standard neutrino interactions via a forward detector like FASERmuC, surpassing current experimental limits.


<details>
  <summary>Details</summary>
Motivation: To explore new non-standard neutrino interactions (NSI) that are beyond the reach of current low-energy experiments and the LHC, leveraging the high-energy and high-flux neutrinos produced in muon colliders.

Method: Proposing the use of a dedicated forward neutrino detector (FASERmuC) in the straight sections of a muon collider to detect neutrino interactions from decaying beam muons, utilizing precise knowledge of neutrino flavor composition and chirality.

Result: The proposed setup can exceed existing and upcoming sensitivity bounds on NSI due to the high neutrino flux, energy, and flavor/chirality information.

Conclusion: Muon colliders offer a unique and powerful opportunity for probing new physics in the neutrino sector through forward neutrino detection, with FASERmuC being a key instrument to exploit this potential.

Abstract: In addition to their broad physics reach enabled by their high energies and
precision, future multi-TeV muon colliders will also be the world's most
intense sources of neutrinos. This offers the opportunity to search for new
non-standard neutrino interactions, possible by installing a dedicated forward
neutrino detector in the straight sections of the collision ring, which is then
used to measure reactions initiated by neutrinos from the decaying beam muons.
In this paper, we show that these searches can exceed current and upcoming
bounds on non-standard neutrino interactions from low-energy precision
experiments and the LHC. This is achieved by the large flux of high-energetic
neutrinos, the precise knowledge of the neutrino flavor composition on each
side of the interaction point and the chirality of the neutrinos. We further
discuss the technical requirements of the proposed forward neutrino detector,
\FASERmuC, to maximally exploit this physics potential.

</details>


### [30] [Latin American network on electromagnetic effects in strongly interacting matter: Contribution to the update of the Latin American Strategy for High Energy, Cosmology and Astroparticle Physics](https://arxiv.org/abs/2508.00771)
*Ana Mizher,Alejandro Ayala*

Main category: hep-ph

TL;DR: This paper highlights the importance of electromagnetic effects on the quark-gluon plasma and summarizes recent contributions from Latin American researchers, emphasizing collaborative efforts through the Latin American Network on Electromagnetic Effects in Strongly Interacting Matter.


<details>
  <summary>Details</summary>
Motivation: To understand how electromagnetic effects influence strongly interacting matter, particularly in extreme environments like the early universe, compact stars, and heavy-ion collisions, where intense electromagnetic fields are present.

Method: Overview of theoretical, phenomenological, and experimental research conducted by the Latin American network, fostering regional and international collaboration.

Result: Summarizes recent scientific contributions from Latin American researchers on electromagnetic effects in the quark-gluon plasma and outlines ongoing and future collaborative activities.

Conclusion: Collaborative efforts within Latin America and with global partners are essential to advance understanding of strongly interacting matter under strong electromagnetic fields, especially in light of upcoming experimental facilities.

Abstract: An accurate characterization of the quark-gluon plasma requires understanding
of how electromagnetic effects affect the processes mediated by the strong
force. All the scenarios in which the plasma emerges, either in nature or in
the laboratory, involve strong electromagnetic fields. The early universe,
compact astrophysical objects, or ultra-relativistic heavy-ion collisions
harbor the most intense fields we know. Researches from the Latin America
region have made a substantial contribution on this subject and the \lq\lq
Latin American Network on Electromagnetic Effects in Strongly Interacting
Matter" aims to cluster efforts to address open questions related to these
systems, boosting collaborations and interaction among its members and
connecting Latin American institutions with institutions from the rest of the
world. In face of the upcoming experimental programs and new facilities, our
mission is to bring together experimentalists, phenomenologists and theorists
to better explore the properties of strongly interacting matter in the presence
of intense electromagnetic fields. This document describes succinctly the
recent contributions from researchers of the Latin American region to the
subject, as well as our activities and perspectives for the future.

</details>


### [31] [Searching for charged Higgs bosons with flavor-changing couplings at the LHC](https://arxiv.org/abs/2508.00764)
*Mohamed Krab*

Main category: hep-ph

TL;DR: The paper explores LHC prospects for discovering charged Higgs bosons in the general two Higgs doublet model with flavor-changing neutral Higgs couplings, focusing on unsuppressed production via the $\rho_{tc}$ coupling and resonant production followed by bosonic decay as a potential signal.


<details>
  <summary>Details</summary>
Motivation: To investigate the discovery potential of charged Higgs bosons at the LHC within the general two Higgs doublet model featuring flavor-changing neutral Higgs couplings, and to explore implications for understanding the baryon asymmetry of the Universe.

Method: Analyzing the resonant production process $c\bar b \to H^+$ induced by the FCNH coupling $\rho_{tc}$, followed by the decay $H^+ \to W^+ H$, assessing its detectability at the LHC.

Result: Sizable $\rho_{tc}$ coupling enables unsuppressed charged Higgs production and could lead to observable signals at the LHC; the $c\bar b \to H^+$ channel with subsequent bosonic decay is identified as a promising discovery route.

Conclusion: Discovery of charged Higgs bosons through resonant $c\bar b$ production and $H^+ \to W^+ H$ decay could signal the presence of the general two Higgs doublet model with flavor-changing neutral Higgs couplings and may provide insights into the origin of baryon asymmetry.

Abstract: We investigate the LHC discovery prospects for charged Higgs bosons in the
general two Higgs doublet model (G2HDM) that has flavor-changing neutral Higgs
(FCNH) couplings. The FCNH $\rho_{tc}$ coupling induces intriguing $H^+$
production processes $c\bar b \to H^+$, $cg \to bH^+$, and $\bar bg \to \bar
cH^+$ without CKM suppression. Sizable $\rho_{tc}$ can drive the disappearance
of antimatter from the Universe. In this contribution, we promote the resonant
$c\bar b \to H^+$ production, followed by the bosonic $H^+ \to W^+ H$ decay.
Discovery could be a harbinger of G2HDM with FCNH couplings, and perhaps shed
light on the baryon asymmetry of the Universe.

</details>


### [32] [$ψ(2S)$ production in jets using NRQCD](https://arxiv.org/abs/2508.00814)
*Marston Copeland,Lin Dai,Yu Fu,Jyotirmoy Roy*

Main category: hep-ph

TL;DR: The study analyzes $\psi(2S)$ production in jets using NRQCD combined with FJF and GFIP formalisms, showing improved agreement with LHCb data over default Pythia+NRQCD; it highlights the utility of $\psi(2S)$ jet distributions in distinguishing between different LDME extractions and reveals significant discrepancies among predictions, suggesting the need for more precise LDME determinations.


<details>
  <summary>Details</summary>
Motivation: To improve the understanding of $\psi(2S)$ production mechanisms in jets by leveraging advanced theoretical frameworks beyond standard Pythia+NRQCD, and to assess the consistency of existing long-distance matrix element (LDME) extractions for $\psi(2S)$.

Method: The analysis uses non-relativistic QCD (NRQCD) combined with the Fragmenting Jet Function (FJF) and Gluon Fragmentation Improved Pythia (GFIP) formalisms to model $\psi(2S)$ production in jets, comparing their predictions with recent LHCb data and evaluating their ability to describe the observed distributions.

Result: Both FJF and GFIP provide a significantly better description of $\psi(2S)$ production data than default Pythia+NRQCD. The $\psi(2S)$ distribution in jets effectively discriminates between different LDME predictions, revealing large discrepancies among extractions from three different collaborations.

Conclusion: Current LDME extractions for $\psi(2S)$ are inconsistent, and more precise determinations are needed. The $\psi(2S)$ production in jets serves as a powerful probe for testing and refining quarkonium production models.

Abstract: Based on recent data from LHCb, we study $\psi(2S)$ production in jets using
non-relativistic QCD (NRQCD) in conjunction with the Fragmenting Jet Function
(FJF) and Gluon Fragmentation Improved Pythia (GFIP) formalisms. Similar to
previous studies of $J/\psi$ production in jets, our results show that these
formalisms offer a much better description of data than the default
Pythia+NRQCD prediction. We compare and contrast between the predictions from
the FJF formalism and the GFIP approach. In addition, our results show that the
distribution of $\psi(2S)$ in jets is an excellent discriminator to test
different predictions for the $\psi(2S)$ LDMEs from various extractions. We
find a large disparity between the predictions from three different
collaborations showing that a more precise extraction of the $\psi(2S)$ LDMEs
may be necessary.

</details>


### [33] [String-based axial and helicity-flip GPDs: a comparison to lattice QCD](https://arxiv.org/abs/2508.00817)
*Florian Hechenberger,Kiminad A. Mamo,Ismail Zahed*

Main category: hep-ph

TL;DR: An analytic string-based model is developed for nucleon axial and helicity flip conformal moments of generalized parton distributions, satisfying key theoretical constraints and matching lattice QCD and experimental data after evolution.


<details>
  <summary>Details</summary>
Motivation: To create a consistent and predictive analytic framework for generalized parton distributions (GPDs) that incorporates both quark and gluon contributions across all skewness values, while respecting fundamental properties like polynomiality and crossing symmetry.

Method: The approach uses Mellin-Barnes resummation of the conformal partial wave expansion, modeling moments via open (Reggeon) and closed string (Pomeron) trajectories with slopes informed by experimental form factors and meson/glueball spectra. The forward limits are constrained by empirical parton distributions, and NLO DGLAP ERBL evolution is applied to match experimental scales.

Result: After NLO evolution to \mu=2\,\text{GeV}, the model reproduces existing lattice results for non-singlet GPD moments, predicts sea quark and gluon polarized moments testable at Jefferson Lab and the EIC, and provides axial and helicity flip GPDs in \emph{x}-space consistent with lattice QCD.

Conclusion: The proposed string-based analytic framework successfully describes key features of GPDs and offers testable predictions for future experiments, bridging theory, lattice simulations, and phenomenology.

Abstract: We construct an analytic, string based representation of the nucleon's axial
and helicity flip conformal moments of generalized parton distributions that
holds for any skewness and for both the quark and gluon channels. The starting
point is the Mellin Barnes resummation of the conformal partial wave expansion,
where the moments are parametrized by open (Reggeon) and closed string
(Pomeron) trajectories with slopes determined by experimental form factors and
meson/glueball spectroscopy. The forward limits are fixed by the empirical
unpolarized and polarized parton distributions. Polynomiality, crossing
symmetry and support are satisfied by construction. After NLO DGLAP ERBL
evolution to $\mu=2$ GeV our analytic framework (i) reproduces some of the
currently available lattice moments of $\mathbb{E}$ and
$\widetilde{\mathbb{H}}$ in the non singlet sector, (ii) predicts sea quark and
gluon polarized moments that will be testable by forthcoming simulations and
experiments at Jefferson Lab and the future EIC, and (iii) yields axial and
helicity flip GPDs in $x$ space in reasonable agreement with lattice QCD.

</details>
