<div id=toc></div>

# Table of Contents

- [cs.SC](#cs.SC) [Total: 2]
- [hep-ph](#hep-ph) [Total: 21]
- [hep-th](#hep-th) [Total: 10]


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [1] [A Variant of Non-uniform Cylindrical Algebraic Decomposition for Real Quantifier Elimination](https://arxiv.org/abs/2508.00505)
*Jasper Nalbach,Erika Ábrahám*

Main category: cs.SC

TL;DR: This paper introduces a new variant of Non-uniform CAD (NuCAD) for real quantifier elimination and SMT solving, provides its implementation, and evaluates it against Cylindrical Algebraic Covering (CAlC).


<details>
  <summary>Details</summary>
Motivation: NuCAD was previously limited to quantifier elimination with no complete implementation; this work aims to extend it for both quantifier elimination and SMT solving, filling a gap in practical real-algebraic problem solving.

Method: The authors develop a novel variant of NuCAD, implement it, and experimentally compare its performance with CAlC, another modern adaptation of CAD.

Result: A complete implementation of NuCAD is achieved for both real quantifier elimination and SMT solving, enabling direct comparison with CAlC.

Conclusion: The proposed NuCAD variant is a viable and practical method for real-algebraic problems, offering a competitive alternative to existing approaches like CAlC.

Abstract: The Cylindrical Algebraic Decomposition (CAD) method is currently the only
complete algorithm used in practice for solving real-algebraic problems. To
ameliorate its doubly-exponential complexity, different exploration-guided
adaptations try to avoid some of the computations. The first such adaptation
named NLSAT was followed by Non-uniform CAD (NuCAD) and the Cylindrical
Algebraic Covering (CAlC). Both NLSAT and CAlC have been developed and
implemented in SMT solvers for satisfiability checking, and CAlC was recently
also adapted for quantifier elimination. However, NuCAD was designed for
quantifier elimination only, and no complete implementation existed before this
work.
  In this paper, we present a novel variant of NuCAD for both real quantifier
elimination and SMT solving, provide an implementation, and evaluate the method
by experimentally comparing it to CAlC.

</details>


### [2] [Projective Delineability for Single Cell Construction](https://arxiv.org/abs/2508.00512)
*Jasper Nalbach,Lucas Michel,Erika Ábrahám,Christopher W. Brown,James H. Davenport,Matthew England,Pierre Mathonet,Naïm Zénaïdi*

Main category: cs.SC

TL;DR: This paper adapts single cell construction in cylindrical algebraic decomposition (CAD) to exploit a weaker notion called projective delineability, reducing computational effort while maintaining completeness, with experimental results provided.


<details>
  <summary>Details</summary>
Motivation: The motivation is to reduce the high computational cost of CAD, which has doubly exponential complexity, by leveraging a weaker but sufficient condition called projective delineability in single cell construction.

Method: The paper adapts the single cell construction paradigm used in CAD-based algorithms (e.g., NLSAT, NuCAD, CAlC) to utilize projective delineability, which requires fewer computations than classical delineability.

Result: The adapted method reduces computational effort in constructing single cells while preserving correctness, and experimental results demonstrate its effectiveness.

Conclusion: Projective delineability can be effectively integrated into single cell construction, offering a more efficient alternative to classical delineability in CAD-based solving, with practical benefits shown experimentally.

Abstract: The cylindrical algebraic decomposition (CAD) is the only complete method
used in practice for solving problems like quantifier elimination or SMT
solving related to real algebra, despite its doubly exponential complexity.
Recent exploration-guided algorithms like NLSAT, NuCAD, and CAlC rely on CAD
technology but reduce the computational effort heuristically. Single cell
construction is a paradigm that is used in each of these algorithms.
  The central property on which the CAD algorithm is based is called
delineability. Recently, we introduced a weaker notion called projective
delineability which can require fewer computations to guarantee, but needs to
be applied carefully. This paper adapts the single cell construction for
exploiting projective delineability and reports on experimental results.

</details>


<div id='hep-ph'></div>

# hep-ph [[Back]](#toc)

### [3] [Reconstructing Transition GPDs for Delta(1232) from Helicity Amplitude A_1/2(Q^2) via Dipole Fits and Impact Parameter Analysis](https://arxiv.org/abs/2508.00018)
*Ralph M. Marinaro III*

Main category: hep-ph

TL;DR: A modular, data-driven reconstruction of the transition GPD $H_T(x,t)$ for the Delta(1232) is presented, using helicity amplitude data and dipole fits to model a separable GPD form that enables Fourier mapping to transverse spatial distributions.


<details>
  <summary>Details</summary>
Motivation: To build a physically interpretable and reproducible model of the transition generalized parton distribution for the Delta(1232) resonance that links experimental amplitude data to spatial quark structure.

Method: Digitized helicity amplitude data and dipole fits to $A_{1/2}(Q^2)$ are used to extract a Sachs-like form factor $F(t)$. A separable GPD model $H_T(x,t) = h(x)F(t)$ is constructed with $h(x)$ as a normalized Beta-like function. The model satisfies the GPD sum rule and allows 2D Fourier transform to obtain transverse spatial distributions $q(x,b)$.

Result: Successful reconstruction of transverse spatial quark distributions for the Delta(1232); analysis reveals how longitudinal momentum shaping affects transverse localization. Spatial features such as mean radius, skewness, and kurtosis are quantified.

Conclusion: The proposed separable, factorized GPD model provides a robust, reproducible framework linking experimental helicity amplitudes to 3D partonic structure, applicable to other transition processes.

Abstract: We present a modular reconstruction of the transition generalized parton
distribution (GPD) H_T(x,t) for the Delta(1232) resonance, based on digitized
helicity amplitude data and dipole fits to A_1/2(Q^2). From the fitted
amplitude, we extract a Sachs-like form factor F(t) and define a separable GPD
model H_T(x, t) = h(x)F(t), with h(x) modeled as a normalized Beta-like
profile. This factorized ansatz satisfies the GPD sum rule and enables a direct
two-dimensional Fourier transform to construct transverse spatial distributions
q(x,b). We analyze how longitudinal shaping modulates transverse localization,
and quantify spatial features using statistical diagnostics including mean
radius, skewness, and kurtosis. The framework is reproducible, data-driven, and
applicable to other transition channels, providing a physically interpretable
map from amplitude behavior to spatial structure.

</details>


### [4] [Dark wounds on icy moons: Ganymede's subsurface ocean as a dark matter detector](https://arxiv.org/abs/2508.00054)
*William DeRocco*

Main category: hep-ph

TL;DR: This paper explores the potential for detecting macroscopic dark matter impacts on Ganymede, leveraging its ancient surface and unique composition. Analytic estimates and simulations show that dark matter collisions could penetrate ice layers, exposing subsurface material distinguishable from asteroid impacts. Upcoming missions like Europa Clipper and JUICE may detect these signatures, offering a novel way to observe dark matter.


<details>
  <summary>Details</summary>
Motivation: Macroscopic dark matter in the mass range of 10^11–10^17 g is poorly constrained. If such dark matter exists, it could collide with planetary bodies like Ganymede, leaving detectable geological features. Ganymede's old surface and differentiated structure make it an ideal candidate for searching such impact signatures.

Method: The authors use analytic modeling to estimate the effects of dark matter impacts on Ganymede, particularly focusing on penetration through the ice layer and ejection of subsurface material. These estimates are validated using iSALE, a multi-material hydrocode for impact simulations. They also assess observational prospects using data from upcoming missions: Europa Clipper and JUICE.

Result: Analytic and simulation results show that dark matter in the considered mass range can penetrate Ganymede's conductive ice layer and excavate subsurface material. The compositional contrast between surface and subsurface layers provides a key observable to distinguish dark matter impacts from asteroid impacts. Upcoming missions may have sufficient resolution and instrumentation to detect such features.

Conclusion: Ganymede is a promising target for detecting macroscopic dark matter through surface impact signatures. The combination of theoretical modeling, simulations, and planned observational missions opens a new avenue for constraining dark matter in an otherwise inaccessible parameter space.

Abstract: Dark matter in the form of macroscopic composites is largely unconstrained at
masses of $\sim 10^{11}- 10^{17}$ g. In this mass range, dark matter may
collide with planetary bodies, depositing an immense amount of energy and
leaving dramatic surface features that remain detectable on geological
timescales. In this paper, we show that Ganymede, the largest Jovian moon,
provides a prime target to search for dark matter impacts due to its
differentiated composition and Gyr-old surface. We study the effects of dark
matter collisions with Ganymede first with analytic estimates, finding that in
a large region of parameter space, dark matter punches through Ganymede's
conductive ice sheet, liberating sub-surface material. This sub-surface
material may be compositionally different from the surface ice, providing a key
observable with which to discriminate asteroid impacts from those caused by
dark matter. We confirm our analytic estimates with dedicated simulations of
dark matter impacts using iSALE, a multi-material impact code. We then discuss
potential detection prospects with two missions currently en route to the
Jovian system, Europa Clipper and JUICE, finding that these missions may have
the ability not only to identify signs of life on the Galilean moons, but signs
of dark matter as well.

</details>


### [5] [Anomaly detection with spiking neural networks for LHC physics](https://arxiv.org/abs/2508.00063)
*Barry M. Dillon,Jim Harkin,Aqib Javed*

Main category: hep-ph

TL;DR: This paper explores the use of Spiking Neural Network (SNN) based AutoEncoders for anomaly detection at the LHC, showing they are competitive with conventional AutoEncoders and well-suited for low-latency, resource-constrained environments like FPGAs.


<details>
  <summary>Details</summary>
Motivation: To develop efficient anomaly detection methods for discovering new physics at the LHC, particularly at the trigger level where conventional selection cuts may discard novel signals.

Method: Design and evaluation of a simple SNN AutoEncoder architecture using the CMS ADC2021 dataset, leveraging the low-latency and low-memory advantages of SNNs on neuromorphic hardware and FPGAs.

Result: SNN AutoEncoders perform competitively with conventional AutoEncoders across all tested signal models for LHC anomaly detection.

Conclusion: SNN-based AutoEncoders are a viable and efficient option for real-time anomaly detection in high-energy physics, especially under strict computational and latency constraints.

Abstract: Anomaly detection offers a promising strategy for discovering new physics at
the Large Hadron Collider (LHC). This paper investigates AutoEncoders built
using neuromorphic Spiking Neural Networks (SNNs) for this purpose. One key
application is at the trigger level, where anomaly detection tools could
capture signals that would otherwise be discarded by conventional selection
cuts. These systems must operate under strict latency and computational
constraints. SNNs are inherently well-suited for low-latency, low-memory,
real-time inference, particularly on Field-Programmable Gate Arrays (FPGAs).
Further gains are expected with the rapid progress in dedicated neuromorphic
hardware development. Using the CMS ADC2021 dataset, we design and evaluate a
simple SNN AutoEncoder architecture. Our results show that the SNN AutoEncoders
are competitive with conventional AutoEncoders for LHC anomaly detection across
all signal models.

</details>


### [6] [Worldline Modeling of Ultra-Intense Lasers for N-photon Scattering Processes](https://arxiv.org/abs/2508.00105)
*Ivan Ahumada,Patrick Copinger,James P. Edwards,Karthik Rajeev*

Main category: hep-ph

TL;DR: The paper presents a first-quantized path integral approach in strong-field QED to non-perturbatively model ultra-intense lasers as background fields, providing compact Master Formulae for N-photon scattering processes for scalars and spinors across various field configurations.


<details>
  <summary>Details</summary>
Motivation: Ultra-intense lasers require modeling beyond standard perturbative methods; existing diagrammatic approaches fail to fully capture strong-field effects non-perturbatively.

Method: The authors use a first-quantized path integral formulation in strong-field QED, treating the laser as a classical background field without perturbation theory, and derive all-multiplicity N-photon scattering amplitudes for complex scalars and spinors.

Result: Compact Master Formulae are obtained for tree-level N-photon scattering in various background fields, including plane waves, impulsive PP-waves, non-null fields, and constant-crossed fields, with low-energy external photons.

Conclusion: The path integral approach provides a powerful non-perturbative framework for strong-field QED processes, enabling efficient computation of multi-photon scattering across diverse background field configurations.

Abstract: The modeling of present and future ultra-intense lasers demands techniques
that go beyond the standard diagrammatic approach to non-perturbatively fully
capture the effects of strong fields. We illustrate the first-quantized path
integral representation for strong-field quantum electrodynamics as a means of
accessing the laser being treated as a background field, which is treated
without recourse to perturbation theory. We examine an all-multiplicity
construction for $N-$photon scattering processes for complex scalars and
spinors, showing compact Master Formulae for tree-level scattering. Several
background fields are considering including: plane waves, impulsive PP-waves,
non-null fields, and homogeneous fields (constant-crossed fields) with
low-energy external photons.

</details>


### [7] [Distinguishing between Dirac and Majorana neutrinos at FASER](https://arxiv.org/abs/2508.00170)
*ShivaSankar K. A.,Alakabha Datta,Danny Marfatia*

Main category: hep-ph

TL;DR: FASER can distinguish between Dirac and Majorana right-handed neutrinos using spatial distributions of electron-positron pairs from three-body decays, with potential 3σ discrimination for ~0.1 GeV RHNs via SMNEFT interactions.


<details>
  <summary>Details</summary>
Motivation: Determine whether right-handed neutrinos are Dirac or Majorana particles, which has profound implications for lepton number conservation and the fundamental nature of neutrinos.

Method: Analyzed kinematic and angular distributions of decay products in the RHN rest frame using Monte Carlo simulations and a chi-squared analysis; focused on RHNs produced from meson decays (B, D, K, pi) at LHC and their decays in FASER.

Result: Significant differences in spatial distributions of electron-positron pairs at FASER between Dirac and Majorana RHNs; discrimination at 3σ level possible for certain operator combinations and RHN masses around 0.1 GeV.

Conclusion: Spatial observables in FASER provide a robust probe to determine the Dirac or Majorana nature of right-handed neutrinos within the SMNEFT framework.

Abstract: Some of the simplest models for the origin of neutrino mass involve
right-handed neutrinos (RHNs), which could be either Dirac or Majorana
particles - a distinction that has profound implications for lepton number
conservation and the fundamental nature of neutrinos. We investigate the
potential of the FASER experiment to distinguish between these two
possibilities using signatures predicted by the Standard Model Neutrino
Effective Field Theory (SMNEFT), where RHNs interact with Standard Model
particles through higher-dimensional operators. We focus on RHNs produced via
$B$, $D$, $K$, and $\pi$ meson decays at the Large Hadron Collider and their
subsequent three-body decays within the FASER detector. The kinematic and
angular distributions of the decay products in the RHN rest frame differ
significantly for Dirac and Majorana RHNs, and these differences manifest as
distinct spatial distributions of electron-positron pairs at FASER. Using Monte
Carlo simulations and a $\chi^2$ analysis, we demonstrate that these spatial
observables provide a robust experimental probe for determining the Dirac or
Majorana nature of RHNs. For select production and decay operator combinations
and RHN masses around 0.1 GeV, FASER can achieve discrimination at the
$3\sigma$ level.

</details>


### [8] [Variational Neural Network Approach to QFT in the Field Basis](https://arxiv.org/abs/2508.00173)
*Kevin Braga,Nobuo Sato,Adam P. Szczepaniak*

Main category: hep-ph

TL;DR: A variational neural network approach is developed to solve the free Klein-Gordon model in momentum space, enabling direct comparison with exact solutions and providing a benchmark for future neural network applications in quantum field theories.


<details>
  <summary>Details</summary>
Motivation: To systematically benchmark neural-network-based variational methods in quantum field theory using the analytically solvable free Klein-Gordon model in momentum space, which has been previously underexplored.

Method: The ground-state wavefunctional is represented by a neural network trained on discretized field configurations by minimizing the Hamiltonian expectation value in momentum space.

Result: Accurate reproduction of key observables such as ground-state energy, two-point correlators, field expectation values, and wavefunctional structure, with quantitative agreement to exact analytic results.

Conclusion: Momentum space is well-suited for benchmarking neural network methods in quantum field theories, and this approach provides a solid foundation for extending to interacting models and position-space formulations.

Abstract: We present a variational neural network approach for solving quantum field
theories in the field basis, focusing on the free Klein-Gordon model formulated
in momentum space. While recent studies have explored neural-network-based
variational methods for scalar field theory in position space, a systematic
benchmark of the analytically solvable Klein-Gordon ground state --
particularly in the momentum-space field basis -- has been lacking. In this
work, we represent the ground-state wavefunctional as a neural network defined
on a discretized set of field configurations and train it by minimizing the
Hamiltonian expectation value. This framework enables direct comparison to
exact analytic results for a range of key observables, including the
ground-state energy, two-point correlators, expectation value of the field, and
the structure of the learned wavefunctional itself. Our results provide
quantitative diagnostics of accuracy and demonstrate the suitability of
momentum space for benchmarking neural network approaches, while establishing a
foundation for future extensions to interacting models and position-space
formulations.

</details>


### [9] [Analytic Solution for the Helicity Evolution Equations at Small $x$ and Large $N_c\&N_f$](https://arxiv.org/abs/2508.00195)
*Jeremy Borden,Yuri V. Kovchegov*

Main category: hep-ph

TL;DR: An exact analytic solution is constructed for revised small-x helicity evolution equations including quark-gluon transitions in the large-Nc&Nf limit, enabling derivation of helicity PDFs, g1 structure function, and polarized DGLAP anomalous dimensions via double-logarithmic resummation; the small-x growth is characterized by an intercept alpha_h determined numerically, with asymptotic expressions and consistency checks confirming agreement with existing calculations.


<details>
  <summary>Details</summary>
Motivation: To improve the theoretical understanding of helicity evolution at small-x by incorporating previously neglected quark-to-gluon and gluon-to-quark transitions, and to provide a consistent framework for resumming double logarithms in polarized parton dynamics within the large-Nc&Nf limit.

Method: Constructed exact analytic solutions of revised small-x helicity evolution equations in the large-Nc&Nf limit; derived double-inverse Laplace transform expressions for helicity PDFs and the g1 structure function; extracted analytic forms of polarized DGLAP anomalous dimensions by resumming powers of alpha_s/omega^2; solved algebraically for the small-x intercept alpha_h and computed asymptotic limits.

Result: Derived analytic expressions for flavor-singlet quark and gluon helicity PDFs, g1 structure function, and four polarized DGLAP anomalous dimensions; found small-x scaling behavior DeltaSigma ~ DeltaG ~ g1 ~ (1/x)^alpha_h with alpha_h from an algebraic equation; computed asymptotic ratios of gluon to quark helicity PDFs; confirmed consistency with known DGLAP results and observed slight discrepancy with infrared evolution equation predictions.

Conclusion: The inclusion of quark-gluon transition terms in the helicity evolution framework leads to consistent, resummed predictions at small-x in the large-Nc&Nf limit, providing new analytic insights into polarized parton dynamics and structure functions, though minor discrepancies with alternative frameworks suggest areas for further study.

Abstract: We construct an exact analytic solution of the revised small-$x$ helicity
evolution equations, where the contributions of the quark-to-gluon and
gluon-to-quark transition operators were newly included. These evolution
equations are written in the large-$N_c\&N_f$ limit and are double-logarithmic,
resumming powers of $\alpha_s\ln^2(1/x)$. Here $N_c$ and $N_f$ are the numbers
of quark colors and flavors, while $\alpha_s$ is the strong coupling constant
and $x$ is the Bjorken-$x$ variable. Using our solution, we obtain analytic
expressions for the flavor singlet quark and gluon helicity parton distribution
functions (PDFs) and for the $g_1$ structure function as double-inverse Laplace
transforms. We also extract analytic expressions for the four DGLAP polarized
anomalous dimensions $\Delta \gamma_{qq}, \Delta \gamma_{qG}, \Delta
\gamma_{Gq}$, and $\Delta \gamma_{GG}$: these expressions resum powers of
$\alpha_s/\omega^2$ to all orders at large-$N_c\&N_f$ (with $\omega$ the Mellin
moment variable). We extract the leading small-$x$ growth of the helicity
distributions, \begin{align} \Delta\Sigma(x,Q^2) \sim \Delta G(x,Q^2)\sim
g_1(x,Q^2) \sim \left(\frac{1}{x}\right)^{\alpha_h}, \end{align} where the
intercept $\alpha_h$ satisfies an algebraic equation. We determine $\alpha_h$
numerically for various values of $N_c$ and $N_f$. We further obtain the
explicit asymptotic expressions for the helicity distributions, which yield
numerical values for the ratio of the gluon helicity PDF to the flavor singlet
quark helicity PDF in the small-$x$ asymptotic limit (for different $N_f/N_c$).
We find that all our predictions for polarized DGLAP anomalous dimensions are
fully consistent with the existing finite-order calculations. Similar to the
large-$N_c$ case, our intercept $\alpha_h$ exhibits a very slight disagreement
with the predictions made within the infrared evolution equations framework.

</details>


### [10] [Neutrino magnetic moment in the doublet-singlet Leptoquark model](https://arxiv.org/abs/2508.00226)
*Ricardo Sánchez-Vélez*

Main category: hep-ph

TL;DR: A simple extension of the Standard Model with two Leptoquarks $S_1$ and $\widetilde{R}_2$ generates a sizable neutrino transition magnetic moment, particularly via bottom quark loops, while remaining consistent with $(g-2)_\mu$, $\text{Br}(\tau \to \mu \gamma)$, $R_{D^{(*)}}$ anomalies, and dark matter direct detection limits.


<details>
  <summary>Details</summary>
Motivation: To explain the neutrino transition magnetic moment and address anomalies in $B$-meson decays $R_{D^{(*)}}$, while incorporating constraints from muon $g-2$ and lepton flavor violation.

Method: Extended Standard Model with two Leptoquarks $S_1$ and $\widetilde{R}_2$; computed contributions to neutrino transition magnetic moment in loop diagrams involving bottom quark; analyzed parameter space using constraints from $(g-2)_\mu$, $\text{Br}(\tau \to \mu \gamma)$, $R_{D^{(*)}}$, and dark matter experiments.

Result: Leptoquarks generate a sizable $\mu_{\nu_{\alpha \beta}}$, especially with bottom quark in loop; large Yukawa couplings are allowed due to parameter degeneracy; model is consistent with $R_{D^{(*)}}$ anomalies and recent XENONnT and LZ limits.

Conclusion: The Leptoquark extension can simultaneously account for enhanced neutrino transition magnetic moments and $B$-decay anomalies while satisfying current experimental constraints from collider and dark matter searches.

Abstract: The neutrino transition magnetic moment $\mu_{\nu_{\alpha \beta}}$ is studied
in a simple extension of the Standard Model. This extension incorporates two
scalar Leptoquarks $S_1$ and $\widetilde{R}_2$ with quantum numbers
$(\bar{3},1,1/3)$ and $(3,2,1/6)$ respectively. It is found that these
Leptoquarks generate a sizable transition magnetic moment, particularly when
the quark bottom is running in the loop. For our analysis of the parameter
space, we include the latest measurement of the muon magnetic moment and
combine it with the experimental constraint on the branching ratio Br$(\tau \to
\mu \gamma)$. We found that, despite the recent agreement on the $(g-2)_\mu$
value, large values for Leptoquark Yukawa couplings are allowed due to a
degeneracy in the parameters. Additionally, we explore how the Leptoquark model
address the anomalies observed in the ratios of semileptonic $B$ mesons decays,
$R_{D^{(*)}}$. We determine that the restrictions derived from our analysis are
consistent with the most recent experimental limits reported by the XENONnT and
LUX-ZEPLIN collaborations. This conclusion is based on our evaluation of the
transition magnetic moment from muon neutrino to tau neutrino, focusing on the
allowed region for the Leptoquark Yukawa couplings.

</details>


### [11] [Thermoelectric figure of merit and the deconfinement phase transition](https://arxiv.org/abs/2508.00407)
*Kamaljeet Singh,Raghunath Sahoo*

Main category: hep-ph

TL;DR: This paper presents the first phenomenological study of the thermoelectric figure of merit (ZT) in hot QCD matter, analyzing its temperature dependence across the hadronic and quark-gluon plasma phases using model-based calculations of transport coefficients.


<details>
  <summary>Details</summary>
Motivation: To gain insight into the microscopic dynamics and redistribution of degrees of freedom in high-temperature QCD matter during the phase transition in relativistic heavy-ion collisions.

Method: Model-based calculations of electrical conductivity, Seebeck coefficient, and thermal conductivity are used to evaluate the temperature dependence of the thermoelectric figure of merit (ZT).

Result: ZT shows nontrivial behavior near the QCD phase transition temperature, reflecting changes in transport properties and active degrees of freedom.

Conclusion: The thermoelectric figure of merit provides a complementary perspective on QCD matter evolution and may offer critical insights into the nature of the phase transition.

Abstract: Thermoelectric phenomena are traditionally associated with the
interconversion of thermal and electrical energy in many-body systems. In the
context of high-temperature quantum chromodynamics (QCD) matter produced in
relativistic heavy-ion collisions, thermoelectric responses can provide insight
into the evolving microscopic dynamics and the redistribution of effective
degrees of freedom across the phase transition region. In this work, for the
first time, we present a phenomenological study of the thermoelectric figure of
merit (\( ZT \)) in hot QCD matter, with a particular focus on its behavior
across the hadronic and quark-gluon plasma phases. Using model-based
calculations for the electrical conductivity, Seebeck coefficient, and thermal
conductivity, we analyze the temperature dependence of \( ZT \) and identify
characteristic features near the QCD phase transition temperature. Our results
indicate that \( ZT \) exhibits nontrivial behavior near the transition region,
reflecting the changing transport properties and active degrees of freedom in
the medium. This phenomenological study of the thermoelectric figure of merit
provides a complementary perspective to traditional transport studies and may
provide critical insights for advancing the understanding of QCD matter through
the transition region.

</details>


### [12] [Jet Image Generation in High Energy Physics Using Diffusion Models](https://arxiv.org/abs/2508.00250)
*Victor D. Martinez,Vidya Manian,Sudhir Malik*

Main category: hep-ph

TL;DR: This paper introduces the first application of diffusion models to generate jet images from proton-proton collision events at the LHC, demonstrating that consistency models outperform score-based diffusion models in fidelity and stability.


<details>
  <summary>Details</summary>
Motivation: To improve the generation of jet images for high-energy physics simulations by leveraging advanced generative models directly in image space.

Method: Mapping kinematic variables of various jet types to 2D jet images and training score-based diffusion and consistency models for class-conditional image generation.

Result: Consistency models achieve higher fidelity and stability than score-based diffusion models, as measured by FID and other metrics.

Conclusion: Diffusion models, especially consistency models, offer efficient and accurate generation of jet images, providing a valuable tool for High Energy Physics research.

Abstract: This article presents, for the first time, the application of diffusion
models for generating jet images corresponding to proton-proton collision
events at the Large Hadron Collider (LHC). The kinematic variables of quark,
gluon, W-boson, Z-boson, and top quark jets from the JetNet simulation dataset
are mapped to two-dimensional image representations. Diffusion models are
trained on these images to learn the spatial distribution of jet constituents.
We compare the performance of score-based diffusion models and consistency
models in accurately generating class-conditional jet images. Unlike approaches
based on latent distributions, our method operates directly in image space. The
fidelity of the generated images is evaluated using several metrics, including
the Fr\'echet Inception Distance (FID), which demonstrates that consistency
models achieve higher fidelity and generation stability compared to score-based
diffusion models. These advancements offer significant improvements in
computational efficiency and generation accuracy, providing valuable tools for
High Energy Physics (HEP) research.

</details>


### [13] [On multi-propagator angular integrals](https://arxiv.org/abs/2508.00693)
*Juliane Haug,Vladimir A. Smirnov,Fabian Wunder*

Main category: hep-ph

TL;DR: The paper introduces an Euler integral representation for multi-propagator angular integrals, develops recursive IBP and dimensional shift relations, and computes four-denominator angular integrals to finite order in ε. It also proposes a decomposition into branch integrals to reduce complexity and derives all-order results for the massless three-denominator case, including soft logarithm resummation.


<details>
  <summary>Details</summary>
Motivation: To extend loop-integral techniques to phase-space integrals without relying on reversed unitarity, enabling more efficient computation of multi-final-state processes.

Method: Develops an Euler (Lee-Pomeransky-like) representation, uses recursive IBP reduction and dimensional shift relations, applies differential equations for master integrals, and introduces a decomposition into branch integrals to reduce the number of scales.

Result: Explicit finite-order ε results for four-denominator angular integrals with arbitrary masses; reduction of scale complexity from (n+1)n/2 to n+1 via branch integrals; all-order ε solution for the massless three-denominator case with soft logarithm resummation.

Conclusion: The proposed framework effectively transfers loop-integral methods to phase-space integrals, enabling systematic and simplified computation of multi-propagator angular integrals with broad applicability in high-energy physics.

Abstract: We study multi-propagator angular integrals, a class of phase-space integrals
relevant to processes with multiple observed final states and a test-bed for
transferring loop-integral technology to phase space integrals without reversed
unitarity. We present an Euler integral representation similar to
Lee-Pomeransky representation and explicitly describe a recursive IBP reduction
and dimensional shift relations for the general case of $n$ denominators. On
the level of master integrals, applying a differential equation approach, we
explicitly calculate the previously unknown angular integrals with four
denominators for any number of masses to finite order in $\varepsilon$.
Extending the idea of dimensional recurrence, we explore the decomposition of
angular integrals into branch integrals reducing the number of scales in the
master integrals from $(n+1)n/2$ to $n+1$. To showcase the potential of this
method, we calculate the massless three denominator integral to establish
all-order results in $\varepsilon$ including a resummation of soft logarithms.

</details>


### [14] [On the gravitational waves from super massive RHNs produced at preheating](https://arxiv.org/abs/2508.00315)
*Shinya Kanemura,Kunio Kaneta,Dibyendu Nanda*

Main category: hep-ph

TL;DR: The paper explores how supermassive particles, like right-handed neutrinos, can be efficiently produced after inflation via non-perturbative processes such as parametric resonance, even when their masses exceed the inflaton mass. These particles emit gravitons through bremsstrahlung during decay, generating a stochastic gravitational wave background. This GW signal carries indirect information about high-scale physics and supermassive particles beyond the Standard Model.


<details>
  <summary>Details</summary>
Motivation: To understand the post-inflationary production of supermassive particles and their impact on the thermal history of the universe, particularly seeking observational signatures of high-scale physics beyond the Standard Model through gravitational waves.

Method: The study uses \alpha-attractor inflationary models and analyzes non-perturbative particle production mechanisms, specifically parametric resonance, focusing on right-handed neutrinos coupled to the inflaton. It calculates the resulting stochastic gravitational wave background generated via graviton bremsstrahlung from decaying right-handed neutrinos.

Result: The model predicts a detectable stochastic gravitational wave spectrum arising from post-inflationary dynamics, which encodes information about the heavy particle sector and the coupling structure, even when the produced particles are too massive to be directly observed.

Conclusion: Gravitational wave observations can serve as a powerful probe of supermassive particles and high-energy physics beyond the Standard Model, offering indirect access to otherwise inaccessible sectors through post-inflationary dynamics in \alpha-attractor models.

Abstract: The post-inflationary production of supermassive particles can have profound
implications for the thermal history of the universe and may leave observable
imprints in the gravitational wave (GW) background. In scenarios where the
inflaton couples predominantly to heavy fields, say right-handed neutrino
(RHN), non-perturbative mechanisms such as parametric resonance can lead to
their efficient production, even when their masses exceed the inflaton mass.
Once produced, the RHNs emit gravitons through bremsstrahlung as they decay
into the Standard Model (SM) particles via $N\rightarrow \ell + H$, enabled by
the unavoidable minimal coupling to gravity, sourcing a stochastic GW
background. We study this mechanism within the framework of $\alpha-$attractor
inflationary models, highlighting how the resulting GW spectrum carries
indirect imprints of the heavy sector and the post-inflationary dynamics. This
offers an observational window into otherwise inaccessible supermassive
particles and provides a powerful probe of high-scale physics beyond the SM.

</details>


### [15] [Latin American network on electromagnetic effects in strongly interacting matter: Contribution to the update of the Latin American Strategy for High Energy, Cosmology and Astroparticle Physics](https://arxiv.org/abs/2508.00771)
*Ana Mizher,Alejandro Ayala*

Main category: hep-ph

TL;DR: Researchers from Latin America are contributing to understanding electromagnetic effects in strongly interacting matter, particularly in quark-gluon plasma under intense electromagnetic fields, and have formed a network to foster collaboration and address open questions in this field.


<details>
  <summary>Details</summary>
Motivation: The quark-gluon plasma is influenced by strong electromagnetic fields present in environments like the early universe, compact stars, and heavy-ion collisions; understanding these effects is crucial for accurate characterization.

Method: The paper outlines collaborative efforts through the 'Latin American Network on Electromagnetic Effects in Strongly Interacting Matter', integrating theoretical, phenomenological, and experimental research.

Result: Recent contributions from Latin American researchers are summarized, along with ongoing activities and future perspectives in studying electromagnetic effects in strongly interacting systems.

Conclusion: The network aims to strengthen regional and international collaboration to advance understanding of strongly interacting matter under extreme electromagnetic conditions, in preparation for upcoming experimental programs.

Abstract: An accurate characterization of the quark-gluon plasma requires understanding
of how electromagnetic effects affect the processes mediated by the strong
force. All the scenarios in which the plasma emerges, either in nature or in
the laboratory, involve strong electromagnetic fields. The early universe,
compact astrophysical objects, or ultra-relativistic heavy-ion collisions
harbor the most intense fields we know. Researches from the Latin America
region have made a substantial contribution on this subject and the \lq\lq
Latin American Network on Electromagnetic Effects in Strongly Interacting
Matter" aims to cluster efforts to address open questions related to these
systems, boosting collaborations and interaction among its members and
connecting Latin American institutions with institutions from the rest of the
world. In face of the upcoming experimental programs and new facilities, our
mission is to bring together experimentalists, phenomenologists and theorists
to better explore the properties of strongly interacting matter in the presence
of intense electromagnetic fields. This document describes succinctly the
recent contributions from researchers of the Latin American region to the
subject, as well as our activities and perspectives for the future.

</details>


### [16] [Analysis of the hadronic molecules $DK$, $D^*K$, $DK^*$ and their bottom analogs with QCD sum rules](https://arxiv.org/abs/2508.00402)
*Ze Zhou,Guo-Liang Yu,Zhi-Gang Wang,Jie Lu*

Main category: hep-ph

TL;DR: The study uses two-point QCD sum rules with color-singlet-color-singlet type currents to predict masses and pole residues of charm-strange and bottom analog tetraquark states with $J^P = 0^+$ and $1^+$. The predicted masses for $DK$, $D^*K$, and $DK^*$ states agree well with known $D_{s}$ mesons, while the $BK$, $B^*K$ states lie above threshold, but $BK^*$ is predicted below threshold, suggesting a possible bound hadronic molecule.


<details>
  <summary>Details</summary>
Motivation: To investigate the nature of charm-strange and bottom analog tetraquark states as possible hadronic molecules using QCD sum rules, particularly focusing on states with $J^P = 0^+$ and $1^+$ quantum numbers.

Method: Two-point QCD sum rules are employed with color-singlet-color-singlet type interpolating currents. Vacuum condensates up to dimension 12 are included in the operator product expansion to improve accuracy.

Result: Predicted masses: $DK$ ($2.322^{+0.066}_{-0.072}$ GeV), $D^*K$ ($2.457^{+0.064}_{-0.068}$ GeV), $DK^*$ ($2.538^{+0.059}_{-0.062}$ GeV) match well with $D_{s0}(2317)$, $D_{s1}(2460)$, and $D_{s1}(2536)$. For bottom analogs: $BK$ ($5.970^{+0.061}_{-0.064}$ GeV), $B^*K$ ($6.050^{+0.062}_{-0.064}$ GeV) are above threshold, while $BK^*$ ($6.158^{+0.061}_{-0.063}$ GeV) is below threshold, suggesting it could be a bound state.

Conclusion: The $DK$, $D^*K$, and $DK^*$ states are consistent with observed $D_s$ mesons, supporting their interpretation as hadronic molecules. The $BK^*$ state, lying below threshold, is a candidate for a bound hadronic molecule, while $BK$ and $B^*K$ are likely not bound.

Abstract: In this work, we construct the color-singlet-color-singlet type currents to
study the masses and pole residues of charm-strange tetraquark states and their
bottom analogs with $J^P$ = $0^+$ and $1^+$ by using two-point QCD sum rules,
where the vacuum condensates are considered up to dimension 12. The predicted
masses for $DK$, $D^*K$ and $DK^*$ molecular states are $2.322_{ - 0.072}^{ +
0.066}$ GeV, $2.457_{ - 0.068}^{ + 0.064}$ GeV and $2.538_{ - 0.062}^{ +
0.059}$ GeV. These results are consistent well with the experimental data of
$D_{s0}(2317)$, $D_{s1}(2460)$ and ${D}_{s1}(2536)$, respectively. The
theoretical results for $BK$ and $B^*K$ molecular states are $5.970_{ -
0.064}^{ + 0.061}$ GeV and $6.050_{ - 0.064}^{ + 0.062}$ GeV which are all
higher than their own thresholds. Finally, the mass of hadronic molecule $BK^*$
is predicted to be $6.158_{ - 0.063}^{ + 0.061}$ GeV. This value is lower than
the threshold of $BK^*$, which implies that it may be a bound hadronic
molecular state.

</details>


### [17] [Rare few-body decays of the Standard Model Higgs boson](https://arxiv.org/abs/2508.00466)
*David d'Enterria,Van Dung Le*

Main category: hep-ph

TL;DR: A comprehensive survey of rare and exclusive Higgs boson decays with branching fractions ≤10⁻⁵ is presented, including theoretical predictions, experimental limits, and HL-LHC projections for ~70 unobserved channels, with 20 new channels involving photons, neutrinos, leptonium, and radiative flavor-changing decays.


<details>
  <summary>Details</summary>
Motivation: To explore rare Higgs decays as probes of Yukawa couplings, flavor-changing interactions, exotic decay backgrounds, and QCD factorization, thereby guiding future experimental and theoretical efforts.

Method: Collection and analysis of theoretical branching fractions for rare Higgs decay channels, incorporating current experimental limits and projected sensitivities at the HL-LHC; computation of 20 new ultrarare decay channels.

Result: Theoretical branching fractions for ~70 rare Higgs decay channels are compiled, with updated experimental limits and HL-LHC projections; 20 new decay channels are computed, including those with photons, neutrinos, leptonium states, and radiative quark-flavor-changing transitions.

Conclusion: This survey provides a valuable resource for prioritizing searches for unobserved Higgs decays, enhancing sensitivity to new physics and validating SM predictions in extreme regimes.

Abstract: We present a survey of rare and exclusive few-body decays of the standard
model (SM) Higgs boson, defined as those into two to four final particles with
branching fractions $\mathcal{B}\lesssim 10^{-5}$. Studies of such decays can
be exploited to constrain Yukawa couplings of quarks and leptons, probe
flavour-changing Higgs decays, estimate backgrounds for exotic Higgs decays
into beyond-SM particles, and/or confirm quantum chromodynamics factorization
with small nonperturbative corrections. We collect the theoretical
$\mathcal{B}$ values for about 70 unobserved Higgs rare decay channels,
indicating their current experimental limits, and estimating their expected
bounds in p-p collisions at the HL-LHC. Among those, we include 20 new decay
channels computed for the first time for ultrarare Higgs boson decays into
photons and/or neutrinos, radiative quark-flavour-changing exclusive decays,
and radiative decays into leptonium states. This survey can help guide and
prioritize upcoming experimental and theoretical studies of unobserved Higgs
boson decays.

</details>


### [18] [Improved Limits on Exotic Interactions Mediated by Axion-Like Particles Between Muons](https://arxiv.org/abs/2508.00504)
*L. Y. Wu,H. Yan*

Main category: hep-ph

TL;DR: Updated constraints on exotic muon interactions are derived from the latest muon anomalous magnetic dipole moment measurement, where the discrepancy between experiment and theory is now $\Delta a_\\mu = (38 \\pm 63) \\times 10^{-11}$, indicating no significant deviation from the Standard Model.


<details>
  <summary>Details</summary>
Motivation: To constrain exotic interactions mediated by new scalar or vector particles using precise measurements of the muon anomalous magnetic dipole moment (AMDM), especially in light of recent experimental and theoretical advances that have reduced the long-standing tension.

Method: Analysis of the latest experimental and theoretical values of the muon AMDM to derive updated bounds on possible exotic interactions involving muons.

Result: The current discrepancy in the muon AMDM is $\\Delta a_\\mu = (38 \\pm 63) \\times 10^{-11}$, leading to tighter constraints on new physics models involving scalar or vector mediators coupling to muons.

Conclusion: The small and statistically insignificant deviation in the muon AMDM from the Standard Model prediction places stronger limits on exotic muon interactions, reducing the parameter space for new physics models.

Abstract: The precise measurement of the muon anomalous magnetic dipole moment (AMDM)
$a_\mu$ provides an opportunity for constraining the exotic interactions
between muons mediated by new scalar or vector particles. Recent progress in
both experimental measurements and theoretical predictions of the muon AMDM has
reconciled the long-standing tension between them. Based on the latest result
for the muon AMDM, $\Delta a_\mu =a^{\rm exp}_\mu-a^{\rm SM}_\mu= (38 \pm 63)
\times 10^{-11}$, we derive updated constraints on exotic interactions between
muons.

</details>


### [19] [The SN 1987A Cooling Bound on Dark Matter Absorption in Electron Targets](https://arxiv.org/abs/2508.00725)
*Claudio Andrea Manzari,Jorge Martin Camalich,Jonas Spinner,Robert Ziegler*

Main category: hep-ph

TL;DR: New supernova cooling bounds on sub-MeV fermionic dark matter are presented, excluding parameter space relevant for direct detection experiments; the analysis is extended to light mediators, where combined constraints still rule out detectable regions.


<details>
  <summary>Details</summary>
Motivation: To constrain sub-MeV fermionic dark matter parameter space relevant for direct detection using SN 1987A cooling, and to assess the impact of light mediators which may alter standard bounds.

Method: Derive cooling bounds from SN 1987A on fermionic dark matter with effective electron couplings; extend analysis to sub-GeV mediators considering resonant production in supernovae and the early Universe.

Result: SN 1987A cooling bounds exclude the sensitivity regions of current and upcoming direct detection experiments for effective couplings; even with light mediators, a combination of supernova and overproduction constraints rules out the entire relevant parameter space.

Conclusion: Supernova cooling and cosmological overproduction constraints strongly limit the viability of sub-MeV dark matter scenarios, rendering them inaccessible to direct detection even in the presence of light mediators.

Abstract: We present new supernova (SN 1987A) cooling bounds on sub-MeV fermionic dark
matter with effective couplings to electrons. These bounds probe the parameter
space relevant for direct detection experiments in which dark matter can be
absorbed by the target material, showing strong complementarity with indirect
searches and constraints from dark matter overproduction. Crucially, our limits
exclude the projected sensitivity regions of current and upcoming direct
detection experiments. Since these conclusions are a priori not valid for light
mediators, we extend our analysis to this case. We show that sub-GeV mediators
can be produced resonantly both in supernova cores and in the early Universe,
altering the SN 1987A analysis for effective couplings. Still, a combination of
supernova cooling constraints and limits from dark matter overproduction
excludes the entire parameter space relevant for direct detection in this case.

</details>


### [20] [Non-Standard Neutrino Interactions at a Muon Collider Neutrino Detector](https://arxiv.org/abs/2508.00761)
*Felix Kling,Yang Ma,Krzysztof Mękała,Jürgen Reuter,Zahra Tabrizi*

Main category: hep-ph

TL;DR: Future multi-TeV muon colliders can serve as intense neutrino sources, enabling sensitive searches for non-standard neutrino interactions using a forward detector like FASERmuC, surpassing current experimental limits.


<details>
  <summary>Details</summary>
Motivation: To explore new physics beyond the Standard Model by detecting non-standard neutrino interactions, which are not accessible with current low-energy experiments or the LHC.

Method: Proposing a dedicated forward neutrino detector (FASERmuC) in the straight sections of a muon collider to capture high-energy neutrinos from decaying beam muons, leveraging precise flavor composition and neutrino chirality.

Result: The proposed setup can exceed existing and upcoming bounds on non-standard neutrino interactions due to the high neutrino flux and precise detection capabilities.

Conclusion: Muon colliders offer a unique and powerful opportunity for advancing neutrino physics through dedicated forward detectors, opening a new frontier in the search for new physics.

Abstract: In addition to their broad physics reach enabled by their high energies and
precision, future multi-TeV muon colliders will also be the world's most
intense sources of neutrinos. This offers the opportunity to search for new
non-standard neutrino interactions, possible by installing a dedicated forward
neutrino detector in the straight sections of the collision ring, which is then
used to measure reactions initiated by neutrinos from the decaying beam muons.
In this paper, we show that these searches can exceed current and upcoming
bounds on non-standard neutrino interactions from low-energy precision
experiments and the LHC. This is achieved by the large flux of high-energetic
neutrinos, the precise knowledge of the neutrino flavor composition on each
side of the interaction point and the chirality of the neutrinos. We further
discuss the technical requirements of the proposed forward neutrino detector,
\FASERmuC, to maximally exploit this physics potential.

</details>


### [21] [Searching for charged Higgs bosons with flavor-changing couplings at the LHC](https://arxiv.org/abs/2508.00764)
*Mohamed Krab*

Main category: hep-ph

TL;DR: The paper explores the LHC's potential to discover charged Higgs bosons in the general two Higgs doublet model with flavor-changing neutral Higgs couplings, focusing on the unsuppressed production process $c\bar b \to H^+$ and its bosonic decay, which could signal new physics related to baryon asymmetry.


<details>
  <summary>Details</summary>
Motivation: To investigate the discovery potential of charged Higgs bosons at the LHC within the general two Higgs doublet model that includes flavor-changing neutral Higgs couplings, and to explore their implications for understanding the baryon asymmetry of the Universe.

Method: Analyzing the resonant production process $c\bar b \to H^+$ induced by the FCNH coupling $\rho_{tc}$, followed by the bosonic decay $H^+ \to W^+ H$, leveraging the absence of CKM suppression for enhanced detectability.

Result: Sizable $\rho_{tc}$ coupling enables unsuppressed charged Higgs production and could lead to observable signals at the LHC; the $c\bar b \to H^+$ channel with $H^+ \to W^+ H$ decay is identified as a promising discovery route.

Conclusion: Discovery of charged Higgs bosons via this channel could indicate the presence of the general two Higgs doublet model with flavor-changing neutral Higgs couplings and may provide insights into the origin of baryon asymmetry in the Universe.

Abstract: We investigate the LHC discovery prospects for charged Higgs bosons in the
general two Higgs doublet model (G2HDM) that has flavor-changing neutral Higgs
(FCNH) couplings. The FCNH $\rho_{tc}$ coupling induces intriguing $H^+$
production processes $c\bar b \to H^+$, $cg \to bH^+$, and $\bar bg \to \bar
cH^+$ without CKM suppression. Sizable $\rho_{tc}$ can drive the disappearance
of antimatter from the Universe. In this contribution, we promote the resonant
$c\bar b \to H^+$ production, followed by the bosonic $H^+ \to W^+ H$ decay.
Discovery could be a harbinger of G2HDM with FCNH couplings, and perhaps shed
light on the baryon asymmetry of the Universe.

</details>


### [22] [$ψ(2S)$ production in jets using NRQCD](https://arxiv.org/abs/2508.00814)
*Marston Copeland,Lin Dai,Yu Fu,Jyotirmoy Roy*

Main category: hep-ph

TL;DR: The study analyzes $\psi(2S)$ production in jets using NRQCD combined with FJF and GFIP formalisms, showing improved agreement with LHCb data over default Pythia+NRQCD; it highlights the utility of $\psi(2S)$ jet distributions in distinguishing between different LDME extractions and reveals significant discrepancies among predictions, suggesting the need for more precise LDME determinations.


<details>
  <summary>Details</summary>
Motivation: To improve the understanding of $\psi(2S)$ production mechanisms in jets by leveraging advanced theoretical frameworks beyond default Pythia+NRQCD, and to assess the consistency of different long-distance matrix element (LDME) extractions for $\psi(2S)$.

Method: The analysis uses non-relativistic QCD (NRQCD) combined with the Fragmenting Jet Function (FJF) and Gluon Fragmentation Improved Pythia (GFIP) formalisms to model $\psi(2S)$ production in jets, comparing their predictions with LHCb data and evaluating their ability to describe observed distributions.

Result: Both FJF and GFIP formalisms provide a better description of $\psi(2S)$ production data than default Pythia+NRQCD; the $\psi(2S)$ jet distribution effectively discriminates between different LDME predictions; significant disparities are found among LDME extractions from three collaborations.

Conclusion: Current LDME extractions for $\psi(2S)$ show large inconsistencies, indicating the need for more precise determinations; the $\psi(2S)$ production in jets serves as a powerful probe for testing and refining quarkonium production models.

Abstract: Based on recent data from LHCb, we study $\psi(2S)$ production in jets using
non-relativistic QCD (NRQCD) in conjunction with the Fragmenting Jet Function
(FJF) and Gluon Fragmentation Improved Pythia (GFIP) formalisms. Similar to
previous studies of $J/\psi$ production in jets, our results show that these
formalisms offer a much better description of data than the default
Pythia+NRQCD prediction. We compare and contrast between the predictions from
the FJF formalism and the GFIP approach. In addition, our results show that the
distribution of $\psi(2S)$ in jets is an excellent discriminator to test
different predictions for the $\psi(2S)$ LDMEs from various extractions. We
find a large disparity between the predictions from three different
collaborations showing that a more precise extraction of the $\psi(2S)$ LDMEs
may be necessary.

</details>


### [23] [String-based axial and helicity-flip GPDs: a comparison to lattice QCD](https://arxiv.org/abs/2508.00817)
*Florian Hechenberger,Kiminad A. Mamo,Ismail Zahed*

Main category: hep-ph

TL;DR: An analytic string-based model for nucleon axial and helicity flip conformal moments of generalized parton distributions is developed using Mellin-Barnes resummation and Regge/Pomeron trajectories, consistent with experimental data and lattice QCD, and makes predictions for sea quark and gluon contributions testable at Jefferson Lab and the EIC.


<details>
  <summary>Details</summary>
Motivation: To develop a consistent analytic framework for generalized parton distributions (GPDs) that accurately describes axial and helicity flip conformal moments across all skewness values and for both quark and gluon channels, while respecting fundamental constraints like polynomiality and crossing symmetry.

Method: The method uses Mellin-Barnes resummation of the conformal partial wave expansion, modeling the moments via open (Reggeon) and closed string (Pomeron) trajectories with slopes informed by experimental form factors and meson/glueball spectroscopy. The forward limits are constrained by empirical unpolarized and polarized parton distributions. The results are evolved to \mu=2\,\text{GeV} using NLO DGLAP-ERBL evolution.

Result: The framework successfully reproduces available lattice QCD moments of \mathbb{E} and \widetilde{\mathbb{H}} in the non-singlet sector, predicts sea quark and gluon polarized moments, and yields axial and helicity flip GPDs in x-space that agree reasonably well with lattice data.

Conclusion: The proposed analytic string-based approach provides a robust and predictive description of nucleon GPDs, offering testable predictions for future experiments at Jefferson Lab and the Electron-Ion Collider (EIC), and bridges theory with lattice and experimental results.

Abstract: We construct an analytic, string based representation of the nucleon's axial
and helicity flip conformal moments of generalized parton distributions that
holds for any skewness and for both the quark and gluon channels. The starting
point is the Mellin Barnes resummation of the conformal partial wave expansion,
where the moments are parametrized by open (Reggeon) and closed string
(Pomeron) trajectories with slopes determined by experimental form factors and
meson/glueball spectroscopy. The forward limits are fixed by the empirical
unpolarized and polarized parton distributions. Polynomiality, crossing
symmetry and support are satisfied by construction. After NLO DGLAP ERBL
evolution to $\mu=2$ GeV our analytic framework (i) reproduces some of the
currently available lattice moments of $\mathbb{E}$ and
$\widetilde{\mathbb{H}}$ in the non singlet sector, (ii) predicts sea quark and
gluon polarized moments that will be testable by forthcoming simulations and
experiments at Jefferson Lab and the future EIC, and (iii) yields axial and
helicity flip GPDs in $x$ space in reasonable agreement with lattice QCD.

</details>


<div id='hep-th'></div>

# hep-th [[Back]](#toc)

### [24] [Total instanton restriction via multiverse interference: Noncompact gauge theories and (-1)-form symmetries](https://arxiv.org/abs/2508.00050)
*Alonso Perez-Lona,Eric Sharpe,Xingyang Yu,Hao Zhang*

Main category: hep-th

TL;DR: This paper explores decomposition in local quantum field theories (QFTs) with a continuous family of universes, enabling the elimination of instantons via topological gauging of (-1)-form symmetry, and applies this to 2D gauge theories and GLSMs, linking anomalies through universe-rotating dyon effects and discussing connections to the adelic solenoid.


<details>
  <summary>Details</summary>
Motivation: To understand how continuous decomposition in local QFTs can consistently remove instantons and clarify dualities and anomalies in two-dimensional gauge theories.

Method: Topological gauging of (-1)-form symmetries, analysis of decomposition in 2D U(1) and R gauge theories, application to GLSMs and the Gross-Taylor string interpretation, and examination of Tanizaki-Unsal-like limits.

Result: Demonstrates that continuous decomposition allows instanton elimination; shows equivalence to using R gauge groups in 2D; clarifies Gross-Taylor interpretation; reveals universe-rotating dyon effects relating anomalies; discusses adelic solenoid as a possible interpretation of certain limits.

Conclusion: Continuous decomposition provides a consistent framework for restricting instantons in local QFTs, with important implications for duality, anomaly matching, and potential connections to number-theoretic structures like the adelic solenoid.

Abstract: In this note we consider examples of decomposition (in which a local QFT is
equivalent to a disjoint union of multiple independent theories, known as
universes) where there is a continuous familiy of universes, rather than a
finite or countably infinite collection. In particular, this allows us to
consistently eliminate all instantons in a local QFT via a suitable topological
gauging of the (-1)-form symmetry. In two-dimensional U(1) gauge theories, this
is equivalent to changing the gauge gruop to R. This makes both locality as
well as the instanton restriction explicit. We apply this to clarify the
Gross-Taylor string interpretation of the decomposition of two-dimensional pure
Yang-Mills. We also apply decomposition to study two-dimensional R gauge
theories, such as the pure R Maxwell theory, and two-dimensional supersymmetric
gauged linear sigma models whose gauge groups have factors of R. In that
context, we find that analogues of the Witten effect for dyons, here rotating
between universes, play a role in relating anomalies of the individual
universes to (different) anomalies in the disjoint union. Finally, we discuss
limits of the Tanizaki-Unsal construction, which accomplish instanton
restriction by topologically gauging a Q/Z (-1)-form symmetry, and speculate in
two-dimensional theories on possible interpretations of those limits in terms
of the adelic solenoid.

</details>


### [25] [Volume as an index of a subalgebra](https://arxiv.org/abs/2508.00056)
*Samuel Leutheusser,Hong Liu*

Main category: hep-th

TL;DR: The paper proposes a 'volume-index' relation, linking the volume of bulk subregions in AdS spacetime to the index of inclusion of boundary operator algebras, offering a new algebraic explanation for black hole interior volume growth and complexity.


<details>
  <summary>Details</summary>
Motivation: To understand the physical meaning of bulk subregion volumes in AdS/CFT through boundary algebraic structures, particularly in the context of black hole interior growth and quantum complexity.

Method: Using subregion-subalgebra duality in AdS/CFT, the authors identify bulk subregions with boundary von Neumann algebras, and propose that the exponential of the maximal volume slice equals the index of inclusion of the corresponding algebras.

Result: A proposed 'volume-index' relation that equates the exponential of the bulk subregion volume to the index of inclusion of boundary subalgebras; this provides a new interpretation of black hole volume growth as an algebraic size change, and applies to entanglement and causal wedges, non-additivity of algebras, and potentially de Sitter space.

Conclusion: The volume of bulk regions can be understood as an emergent algebraic quantity via the index of inclusion, offering a new perspective on spacetime geometry, complexity growth, and quantum gravity in holography.

Abstract: We propose a new way to understand the volume of certain subregions in the
bulk of AdS spacetime by relating it to an algebraic quantity known as the
index of inclusion. This index heuristically measures the relative size of a
subalgebra $\mathcal{N}$ embedded within a larger algebra $\mathcal{M}$.
According to subregion-subalgebra duality, bulk subregions are described by von
Neumann algebras on the boundary. When a causally complete bulk subregion
corresponds to the relative commutant $\mathcal{N}' \cap \mathcal{M}$ -- the
set of operators in $\mathcal{M}$ that commute with $\mathcal{N}$ -- of
boundary subalgebras, we propose that the exponential of the volume of the
maximal volume slice of the subregion equals the index of inclusion. This
``volume-index'' relation provides a new boundary explanation for the growth of
interior volume in black holes, reframing it as a change in the relative size
of operator algebras. It offers a complementary perspective on complexity
growth from the Heisenberg picture, and has a variety of other applications,
including quantifying the relative size of algebras dual to the entanglement
wedge and the causal wedge of a boundary region, as well as quantifying the
violation of additivity of operator algebras in the large $N$ limit. Finally,
it may offer insights into the volume growth of de Sitter space through the
changes in North and South pole observer algebras in time.

</details>


### [26] [Entanglement spreading and emergent locality in Brownian SYK chains](https://arxiv.org/abs/2508.00060)
*Onkar Parrikar,Jatin Narde,Harshit Rajgadia,Sandip Trivedi*

Main category: hep-th

TL;DR: The paper studies the spread of quantum information in a 1D Brownian SYK chain using quantum error correction tools, showing that information spreads within a sharp light-cone defined by the butterfly velocity, consistent with holographic principles and described by the FKPP equation.


<details>
  <summary>Details</summary>
Motivation: To understand how quantum information spreads in chaotic systems and how emergent locality arises, which is essential for the existence of a geometric bulk dual in holography.

Method: Used quantum error correction frameworks to analyze information spread in a 1D Brownian SYK chain; calculated information content of a qudit in an interval after injection at t=0, and linked the dynamics to the FKPP equation.

Result: Found a sharp transition in information content at a distance ℓ ∼ v_B T, indicating a light-cone-like spread; this sharp front emerges at strong coupling and late times, governed by the FKPP equation.

Conclusion: Emergent locality and sharp light-cone propagation of quantum information can be analytically demonstrated in chaotic systems, supporting the holographic principle and the RT formula's implications via quantum error correction.

Abstract: The Ryu-Takayanagi (RT) formula and its interpretation in terms of quantum
error correction (QEC) implies an emergent locality for the spread of quantum
information in holographic CFTs, where information injected at a point in the
boundary theory spreads within a sharp light-cone corresponding to the
butterfly velocity. This emergent locality is a necessary condition for the
existence of a geometric bulk dual with an RT-like formula for entanglement
entropy. In this paper, we use tools from QEC to study the spread of quantum
information and the emergence of a sharp light-cone in an analytically
tractable model of chaotic dynamics, namely a one-dimensional Brownian SYK
chain. We start with an infinite temperature state in this model and inject a
qudit at time $t=0$ at some point $p$ on the chain. We then explicitly
calculate the amount of information of the qudit contained in an interval of
length $2\ell$ (centered around $p$) at some later time $t=T$. We find that at
strong coupling, this quantity shows a sharp transition as a function of $\ell$
from near zero to near maximal correlation. The transition occurs at $\ell \sim
v_B T$, with $v_B$ being the butterfly velocity. Underlying the emergence of
this sharp light-cone is a non-linear generalization of the diffusion equation
called the FKPP equation, which admits sharp domain wall solutions at late
times and strong coupling. These domain wall solutions can be understood on
physical grounds from properties of operator growth in chaotic systems.

</details>


### [27] [The CFT of Sen's Formulation of Chiral Gauge Fields](https://arxiv.org/abs/2508.00199)
*Chris Hull,Neil Lambert*

Main category: hep-th

TL;DR: The paper discusses Sen's action for chiral bosons in 2D and its generalization using two metrics, linking it to a non-unitary c=2 CFT and proposing a 'bosonisation' interpretation. It extends the framework to higher dimensions with self-dual gauge fields and bi-metric actions, connecting to BF-type and democratic actions for p-form fields.


<details>
  <summary>Details</summary>
Motivation: To generalize Sen's action for chiral bosons by introducing a second arbitrary metric, enabling formulation on curved world-sheets, and to explore its connections to conformal field theories, bosonisation, and higher-dimensional self-dual gauge theories.

Method: Analyzing Sen's action with two metrics, studying its reduction to known theories (e.g., beta-gamma systems), identifying vertex and line operators, deriving correlation functions, and extending the bi-metric framework to higher-dimensional self-dual gauge fields and democratic actions.

Result: The flat metric in Sen's action can be generalized to an arbitrary metric, allowing curved world-sheet formulation. When metrics coincide, the theory reduces to a non-unitary c=2 CFT. A bosonisation-like relation is identified. In d=4k+2, the bi-metric action reduces to a BF-type theory with self-dual fields, representing two self-dual gauge fields. A democratic action for p-forms is proposed.

Conclusion: Sen's action can be generalized using two metrics, providing a broader framework for chiral bosons and self-dual gauge fields, with connections to CFTs, bosonisation, and topological-like theories in various dimensions.

Abstract: Sen's action for chiral bosons in 2 dimensions describes two chiral scalars,
one of which couples to the physical metric and one of which couples to a flat
metric. It has a generalisation in which the flat metric is replaced by an
arbitrary second metric and so can be formulated on any curved world-sheet.
When the two metrics are equal, the theory reduces to a $\beta \gamma$ system,
giving a non-unitary $c=2$ conformal field theory. We argue that the relation
between this and the theory of two chiral bosonic scalars of the same chirality
can be viewed as a \lq bosonisation'. We show that the standard vertex
operators for the chiral scalars are vertex operators and line operators in the
Sen formulation and derive the formulation in the Sen theory of correlation
functions in the chiral scalar theory. The flat space Sen theory can be coupled
to two different world-sheet metrics in such a way that one scalar couples to
one metric and the other to the other metric, so obtaining the general
formulation with two metrics.
  In $d=4k+2$ dimensions, the bi-metric action for a $2k$-form gauge field with
self-dual field strength reduces, when the two metrics are equal, to a
conformal field theory with a $BF$-type action, except that $B$ is a self-dual
$d/2$-form and $F$ is a $d/2$-form field strength, $F=dP$. The self-duality of
$B$ means that this is not a topological theory but instead represents two
self-dual gauge fields. This has a generalisation to a democratic action for
$p$-form gauge fields in any dimension.

</details>


### [28] [Holographic Wilson Loop One-point Functions in ABJM Theory](https://arxiv.org/abs/2508.00281)
*Xiao-Yi Zhang,Yunfeng Jiang,Jun-Bao Wu*

Main category: hep-th

TL;DR: The paper computes correlation functions between a BPS Wilson loop and local operators in ABJM theory using its M-theory dual, showing agreement with supersymmetric localization in the large-N limit.


<details>
  <summary>Details</summary>
Motivation: To understand the correlation between Wilson loops and local operators in ABJM theory via holography and verify consistency with field theory results from localization.

Method: Used AdS/CFT correspondence, modeling the correlators as fluctuations of a probe M2-brane in AdS_4 x S^7/Z_k, and derived analytic results for 1/3-BPS chiral primaries and the stress-energy tensor.

Result: Obtained analytic expressions for the correlation functions that match existing localization results in the large-N limit with finite k.

Conclusion: Holographic computation in M-theory provides results consistent with supersymmetric localization, supporting the AdS/CFT duality in ABJM theory.

Abstract: We compute the correlation function between a circular half-BPS Wilson loop
(or straight Wilson line) and a local operator in ABJM theory utilizing its
M-theory description. The local operator can be a $1/3$-BPS single-trace chiral
primary operator or the stress-energy tensor. Using the AdS/CFT correspondence,
these correlators are dual to fluctuations of a probe M2-brane in $AdS_4 \times
S^7/\mathbb{Z}_k$. We derive analytic results for both cases and compare them
with existing results based on supersymmetric localization in the literature.
In the large-$N$ limit with $k$ finite, our holograkphic results exhibit
perfect agreement with localization.

</details>


### [29] [Quasi-Normal Modes and Nonlinear Electrodynamics in Black Hole Phase Transitions](https://arxiv.org/abs/2508.00404)
*Zi-Yu Hou,Yu-Qi Lei,Xian-Hui Ge*

Main category: hep-th

TL;DR: The study explores the link between thermodynamic phase transitions and quasi-normal modes (QNMs) in charged black holes within $F(R)$-Euler-Heisenberg gravity, showing that QNM behavior reflects thermodynamic phase changes, especially via the slope parameter $K$, with correspondence influenced by angular quantum number $l$ and overtone number $n€.


<details>
  <summary>Details</summary>
Motivation: To understand whether thermodynamic phase transitions in black holes are connected to their dynamical properties, specifically through quasi-normal modes in a generalized gravity framework with nonlinear electromagnetic fields.

Method: Analyzed the quasi-normal modes (QNMs) of massless scalar fields in charged black holes with positive curvature in $F(R)$-Euler-Heisenberg gravity, and compared the QNM spectral features (especially the slope parameter $K$) with thermodynamic phase transitions identified via heat capacity.

Result: The transition point in the QNM slope parameter $K$ aligns with the thermodynamic phase transition point as indicated by heat capacity, within computational uncertainty. This match persists across varying curvature and charge parameters. Higher angular quantum number $l$ weakens the correspondence, while larger overtone number $n$ restores it beyond a threshold.

Conclusion: Thermodynamic phase transitions in black holes encode dynamical information in their QNMs, revealing a robust connection between thermodynamic and dynamical properties in curved black hole spacetimes with nonlinear electrodynamics.

Abstract: We investigate the connection between thermodynamic phase transitions and
quasi-normal modes (QNMs) in charged black holes with a positive curvature
constant, within the framework of $F(R)$-Euler-Heisenberg gravity. Nonlinear
electromagnetic fields lead to rich thermodynamic phase structures and
significantly affect the QNMs of massless scalar fields. By analyzing the QNMs
spectrum, we find that the transition point marking the disappearance of
divergence in the QNMs slope parameter $K$ aligns with the change of the
thermodynamic phase structure described by the heat capacity, within the bounds
of computational uncertainty. This precise matching holds under variations of
curvature parameters and charge. Furthermore, we show that larger angular
quantum number $l$ diminishes this correspondence, while higher overtone number
$n$ restores it beyond a threshold. These findings demonstrate that
thermodynamic phase transitions of black holes carry embedded dynamical
information, uncovering a fundamental link between black hole thermodynamic and
dynamical properties.

</details>


### [30] [Aspects of 4d $\mathcal{N}=1$ $ADE$ gauge theories from M-theory: decomposition, automorphisms, and generalised symmetries](https://arxiv.org/abs/2508.00564)
*Osama Khlaif,Marwan Najjar*

Main category: hep-th

TL;DR: The paper studies the decomposition of 4d N=1 gauge theories with specific Lie algebras using M-theory geometric engineering, revealing novel structures through automorphisms and analyzing their p-form and (-1)-form symmetries, SymTFTs, instanton sums, and higher 4-group structures derived from M-theory.


<details>
  <summary>Details</summary>
Motivation: To understand the decomposition structure of 4d N=1 gauge theories with su(N), so(2N), and e6 algebras via M-theory and explore how automorphisms lead to new gauge theories and symmetry structures.

Method: Using M-theory geometric engineering, the authors analyze gauge theories arising from quotienting the Bryant-Salamon spin bundle over the 3-sphere by finite subgroups, and study their symmetries and topological structures via symmetry topological field theories (SymTFTs) and M-theoretic defects.

Result: The theories exhibit both inner and outer automorphisms leading to decompositions into so(2N+1), sp(2N), f4, and g2 gauge algebras; the paper derives p-form and (-1)-form symmetries, constructs SymTFTs, identifies M-theory origins of symmetry operators, and finds modified instanton sums and higher 4-group structures.

Conclusion: The decomposition of 4d N=1 gauge theories via M-theory reveals rich symmetry and topological structures, extending to non-simply-laced algebras and providing a direct M-theoretic derivation of higher categorical symmetries and topological sectors.

Abstract: We study the decomposition of 4d $\mathcal{N}=1$ gauge theories with Lie
algebras of type $\mathfrak{su}(N)$, $\mathfrak{so}(2N)$, and
$\mathfrak{e}_{6}$, realized via M-theory geometric engineering. These
theories, together with their novel decomposition structure, arise from
quotienting the Bryant--Salamon spin bundle over the 3-sphere by special finite
subgroups acting simultaneously on both the fiber and base. We show that these
gauge theories admit both inner and outer automorphisms, enabling sequences of
gauge theory breaking. In particular, outer automorphisms extend the
decomposition structure to theories with $\mathfrak{so}(2N+1)$,
$\mathfrak{sp}(2N)$, $\mathfrak{f}_{4}$, and $\mathfrak{g}_{2}$ gauge algebras.
For these theories, including both simply-laced and non-simply-laced cases, we
analyze their $p$-form symmetries, including $(-1)$-form symmetries, derive the
corresponding SymTFTs, and identify the M-theoretic origin of their symmetry
topological operators and defects. Finally, we demonstrate that these gauge
theories exhibit modified instanton sums and higher 4-group structures, and we
derive the associated topological sector directly from M-theory.

</details>


### [31] [Higher spin fields and the field strength multicopy](https://arxiv.org/abs/2508.00711)
*Graham R. Brown,Bill Spence*

Main category: hep-th

TL;DR: The paper explores the generalisation of the Weyl double copy to higher spin multi-copies, linking higher spin field strengths to powers of the Maxwell tensor in Kerr-Schild spacetimes, with insights from spinor formalisms and connections to the Penrose transform, while also examining higher-dimensional cases and continuous spin representations in various backgrounds.


<details>
  <summary>Details</summary>
Motivation: To extend the Weyl double copy framework to higher spin fields and explore its implications in different dimensions and spacetime backgrounds, particularly using spinor methods and vector superspace formalisms.

Method: The authors use linearised higher spin field strengths in spacetimes with Kerr-Schild coordinates, employ spinor descriptions in four and higher dimensions, relate results to the Penrose transform, and analyse the vector superspace formalism for higher and continuous spin representations, including in anti-de Sitter space.

Result: The paper establishes a higher spin 'multi-copy' relation involving powers of the Maxwell tensor, shows how Fronsdal equations ensure tracelessness, clarifies the structure in four dimensions via spinors, explores higher-dimensional spinor multicopy with new features from little group analysis, and integrates Kerr-Schild higher spin fields into a simple vector superspace expression when the continuous spin parameter is zero; it also presents a general Kerr-Schild solution in AdS and discusses limitations for continuous spin formulations.

Conclusion: The Weyl double copy can be generalised to higher spins in a structured way using Kerr-Schild geometries and spinor methods, with promising connections to higher-dimensional and continuous spin theories, though challenges remain for fully describing continuous spin in this framework.

Abstract: We discuss the generalisation of the Weyl double copy to higher spin
"multi-copies", showing how the natural linearised higher spin field strengths
can be related to sums of powers of the Maxwell tensor. The tracelessness of
the field strength involves the appropriate Fronsdal equations of motion for
the higher spin field. We work with spacetimes admitting Kerr-Schild
coordinates and give a number of examples in different dimensions. We note that
the multi-copy is particularly transparent in four dimensions if one uses
spinor descriptions of the fields, relating this to the Penrose transform. The
higher-dimensional spinor multicopy is also explored and reveals some
interesting new features arising from the little group based identification of
higher spin field strengths and Maxwell tensor types. We then turn to the
vector superspace formalism describing higher spin and `continuous' spin
representations given by Schuster and Toro, based on symmetric tensor fields.
Here the Kerr-Schild higher spin fields we have used earlier naturally package
into a simple expression involving an arbitrary function, when the continuous
spin scale $\rho$ is set to zero. Further, we discuss the case of an anti-de
Sitter background, where there is also a vector space formalism given by Segal
and we clarify this approach using a different definition of the covariant
derivative. We give a general solution of Kerr-Schild type and finally we
describe some of the obstacles to a continuous spin formulation.

</details>


### [32] [Gauge symmetry and radiatively induced terms in dimension-5 non-minimal Lorentz-violating QED](https://arxiv.org/abs/2508.00801)
*A. P. B. Scarpelli,A. R. Vieira*

Main category: hep-th

TL;DR: This paper establishes the conditions for gauge invariance in a non-minimal dimension-5 Lorentz-violating QED, showing they are identical to those in standard QED, and demonstrates that a fermion-sector Lorentz-violating term can radiatively induce a similar term in the photon sector.


<details>
  <summary>Details</summary>
Motivation: To understand the conditions under which gauge invariance is preserved in a non-minimal Lorentz-violating extension of QED, and to explore the interplay between Lorentz violation in fermion and photon sectors.

Method: Computed one-loop two- and three-point functions, checked gauge Ward identities, and analyzed radiative induction of terms between sectors.

Result: The conditions for gauge invariance in the non-minimal Lorentz-violating QED are the same as in standard QED; the fermion-sector $a^{(5)}_F$-term induces a non-minimal Lorentz-violating term in the photon sector.

Conclusion: Gauge symmetry in this extended framework is preserved under the same conditions as usual QED, and cross-sector radiative induction of Lorentz-violating terms is possible.

Abstract: In this work, we derive the conditions that assure gauge invariance of a
non-minimal dimension-5 Lorentz-violating QED. The two and three point
functions at one-loop are computed. The gauge Ward identities are checked and
the conditions to assure gauge symmetry of this non-minimal framework is found
to be the same of the usual QED. Induced terms are also investigated and it is
shown that the non-minimal Lorentz-violating $a^{(5)}_F$-term of the fermion
sector can induce radiatively a non-minimal Lorentz-violating term in the
photon sector.

</details>


### [33] [Proper-time functional renormalization in $O(N)$ scalar models coupled to gravity](https://arxiv.org/abs/2508.00807)
*Alfio Bonanno,Emiliano Glaviano,Gian Paolo Vacca*

Main category: hep-th

TL;DR: The study uses a functional Wilsonian renormalization group with a proper time regulator to explore scaling solutions and critical properties of an O(N)-invariant scalar field coupled to gravity in 3D and 4D, confirming prior results from an effective average action approach with minor differences in critical exponents, especially in finite and large N limits.


<details>
  <summary>Details</summary>
Motivation: To test the functional Wilsonian renormalization group with a proper time regulator in studying scaling solutions and critical behavior of O(N) scalar fields coupled to gravity, and compare findings with previous results obtained using the effective average action framework.

Method: Applied the functional Wilsonian renormalization group with proper time regulator, using the same background-fluctuation splitting and gauge fixing as in prior work based on the effective average action; employed similar truncations of the effective action for comparison in d=3 and d=4 dimensions.

Result: Most scaling solutions and critical exponents are consistent with prior results at both qualitative and quantitative levels; however, small differences appear in both finite N and large N limits, depending on the 'improved' schemes used in each framework.

Conclusion: The functional Wilsonian RG with proper time regulator is a reliable tool for studying quantum gravity coupled to scalar fields, largely confirming earlier findings, though scheme-dependent differences highlight the need for careful comparison across methods.

Abstract: We focus on the use of the functional Wilsonian renormalization group
framework characterized by a proper time regulator and test its use in the
search of the scaling solutions and the critical properties of an
O(N)-invariant scalar field multiplet coupled to gravity in d=4 and d=3
dimensions. We employ the same background-fluctuation splitting and gauge
fixing procedure, already adopted in a previous study based, instead, on the
effective average action framework and a similar truncation of the effective
action. Our main goal is to compare the results for the scaling solutions and
some of the associated critical exponents. In this analysis, performed in a
different framework, most of the picture previously uncovered is confirmed both
at qualitative and quantitative level. There are, neverthelss, few differences
both at finite N and in its large value limit, depending also on the schemes
which in both frameworks are called 'improved'

</details>
